{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN - NSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sharuka Thirimanne\\Desktop\\FYP-ML-IDS\n"
     ]
    }
   ],
   "source": [
    "cd C:\\\\Users\\\\Sharuka Thirimanne\\\\Desktop\\\\FYP-ML-IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sharuka thirimanne\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\sharuka thirimanne\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\sharuka thirimanne\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\sharuka thirimanne\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\sharuka thirimanne\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\sharuka thirimanne\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import Model, layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report,confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_train_dataset():\n",
    "    df_train = pd.read_csv('NSL_train-set.csv')\n",
    "    \n",
    "    limit = df_train.shape[1]-1\n",
    "    \n",
    "    X_train = df_train.iloc[:,0:limit]\n",
    "    Y_train = df_train.iloc[:,limit]\n",
    "    \n",
    "    return X_train, Y_train, df_train\n",
    "\n",
    "X_train, Y_train, df_train = load_train_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_dataset():\n",
    "    df_test = pd.read_csv('NSL_test-set.csv')\n",
    "\n",
    "    limit = df_test.shape[1]-1\n",
    "    \n",
    "    X_test = df_test.iloc[:,0:limit]\n",
    "    Y_test = df_test.iloc[:,limit]\n",
    "    \n",
    "    return X_test, Y_test, df_test\n",
    "\n",
    "X_test, Y_test, df_test = load_test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training X   : (99854, 62)\n",
      "Validation X : (6942, 62)\n",
      "Test_X       : (22310, 62)\n",
      "Training_Y   : (99854,)\n",
      "Validation Y : (6942,)\n",
      "Test_Y       : (22310,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val , Y_train , Y_val = train_test_split(X_train,Y_train, test_size=0.065,stratify = Y_train,shuffle=True,random_state=42)\n",
    "\n",
    "print('Training X   :',X_train.shape)\n",
    "print('Validation X :',X_val.shape)\n",
    "print('Test_X       :',X_test.shape)\n",
    "print('Training_Y   :',Y_train.shape)\n",
    "print('Validation Y :',Y_val.shape)\n",
    "print('Test_Y       :',Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [ \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='accuracy', \n",
    "    verbose=1,\n",
    "    patience=5,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network():\n",
    "    #Neural Network Model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=62, activation='relu',kernel_initializer='glorot_uniform',\n",
    "                    bias_initializer='zeros',kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='SGD', metrics = METRICS)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 99854 samples, validate on 6942 samples\n",
      "Epoch 1/200\n",
      "99854/99854 [==============================] - 3s 28us/step - loss: 5.4672 - accuracy: 0.8642 - precision: 0.9773 - recall: 0.7441 - auc: 0.9290 - val_loss: 4.5688 - val_accuracy: 0.9239 - val_precision: 0.9762 - val_recall: 0.8690 - val_auc: 0.9681\n",
      "Epoch 2/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 3.9419 - accuracy: 0.9372 - precision: 0.9761 - recall: 0.8963 - auc: 0.9747 - val_loss: 3.3843 - val_accuracy: 0.9458 - val_precision: 0.9770 - val_recall: 0.9131 - val_auc: 0.9792\n",
      "Epoch 3/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 2.9297 - accuracy: 0.9504 - precision: 0.9782 - recall: 0.9215 - auc: 0.9817 - val_loss: 2.5247 - val_accuracy: 0.9539 - val_precision: 0.9793 - val_recall: 0.9275 - val_auc: 0.9838\n",
      "Epoch 4/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 2.1922 - accuracy: 0.9562 - precision: 0.9800 - recall: 0.9315 - auc: 0.9852 - val_loss: 1.8971 - val_accuracy: 0.9581 - val_precision: 0.9807 - val_recall: 0.9346 - val_auc: 0.9864\n",
      "Epoch 5/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 1.6533 - accuracy: 0.9594 - precision: 0.9812 - recall: 0.9368 - auc: 0.9873 - val_loss: 1.4383 - val_accuracy: 0.9607 - val_precision: 0.9817 - val_recall: 0.9388 - val_auc: 0.9882\n",
      "Epoch 6/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 1.2588 - accuracy: 0.9616 - precision: 0.9821 - recall: 0.9403 - auc: 0.9888 - val_loss: 1.1025 - val_accuracy: 0.9624 - val_precision: 0.9825 - val_recall: 0.9416 - val_auc: 0.9894\n",
      "Epoch 7/200\n",
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.9696 - accuracy: 0.9631 - precision: 0.9828 - recall: 0.9426 - auc: 0.9898 - val_loss: 0.8552 - val_accuracy: 0.9637 - val_precision: 0.9830 - val_recall: 0.9437 - val_auc: 0.9902\n",
      "Epoch 8/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 0.7572 - accuracy: 0.9642 - precision: 0.9832 - recall: 0.9445 - auc: 0.9906 - val_loss: 0.6743 - val_accuracy: 0.9647 - val_precision: 0.9835 - val_recall: 0.9452 - val_auc: 0.9909\n",
      "Epoch 9/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 0.6010 - accuracy: 0.9651 - precision: 0.9836 - recall: 0.9459 - auc: 0.9912 - val_loss: 0.5407 - val_accuracy: 0.9655 - val_precision: 0.9838 - val_recall: 0.9465 - val_auc: 0.9914\n",
      "Epoch 10/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 0.4860 - accuracy: 0.9658 - precision: 0.9840 - recall: 0.9469 - auc: 0.9916 - val_loss: 0.4430 - val_accuracy: 0.9661 - val_precision: 0.9842 - val_recall: 0.9475 - val_auc: 0.9919\n",
      "Epoch 11/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 0.4011 - accuracy: 0.9664 - precision: 0.9843 - recall: 0.9479 - auc: 0.9920 - val_loss: 0.3698 - val_accuracy: 0.9667 - val_precision: 0.9844 - val_recall: 0.9484 - val_auc: 0.9922\n",
      "Epoch 12/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 0.3384 - accuracy: 0.9669 - precision: 0.9845 - recall: 0.9488 - auc: 0.9924 - val_loss: 0.3167 - val_accuracy: 0.9672 - val_precision: 0.9846 - val_recall: 0.9491 - val_auc: 0.9925\n",
      "Epoch 13/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 0.2922 - accuracy: 0.9674 - precision: 0.9847 - recall: 0.9494 - auc: 0.9926 - val_loss: 0.2778 - val_accuracy: 0.9676 - val_precision: 0.9848 - val_recall: 0.9498 - val_auc: 0.9928\n",
      "Epoch 14/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 0.2578 - accuracy: 0.9678 - precision: 0.9849 - recall: 0.9501 - auc: 0.9929 - val_loss: 0.2471 - val_accuracy: 0.9680 - val_precision: 0.9850 - val_recall: 0.9504 - val_auc: 0.9930\n",
      "Epoch 15/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 0.2322 - accuracy: 0.9681 - precision: 0.9850 - recall: 0.9507 - auc: 0.9931 - val_loss: 0.2268 - val_accuracy: 0.9683 - val_precision: 0.9851 - val_recall: 0.9510 - val_auc: 0.9932\n",
      "Epoch 16/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 0.2132 - accuracy: 0.9684 - precision: 0.9852 - recall: 0.9512 - auc: 0.9933 - val_loss: 0.2082 - val_accuracy: 0.9686 - val_precision: 0.9852 - val_recall: 0.9515 - val_auc: 0.9934\n",
      "Epoch 17/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 0.1990 - accuracy: 0.9687 - precision: 0.9853 - recall: 0.9517 - auc: 0.9934 - val_loss: 0.1968 - val_accuracy: 0.9689 - val_precision: 0.9854 - val_recall: 0.9519 - val_auc: 0.9935\n",
      "Epoch 18/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 0.1884 - accuracy: 0.9690 - precision: 0.9854 - recall: 0.9521 - auc: 0.9936 - val_loss: 0.1874 - val_accuracy: 0.9691 - val_precision: 0.9855 - val_recall: 0.9523 - val_auc: 0.9937\n",
      "Epoch 19/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1803 - accuracy: 0.9693 - precision: 0.9855 - recall: 0.9525 - auc: 0.9937 - val_loss: 0.1803 - val_accuracy: 0.9694 - val_precision: 0.9856 - val_recall: 0.9527 - val_auc: 0.9938\n",
      "Epoch 20/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1742 - accuracy: 0.9695 - precision: 0.9856 - recall: 0.9528 - auc: 0.9939 - val_loss: 0.1743 - val_accuracy: 0.9696 - val_precision: 0.9857 - val_recall: 0.9530 - val_auc: 0.9939\n",
      "Epoch 21/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1694 - accuracy: 0.9697 - precision: 0.9857 - recall: 0.9532 - auc: 0.9940 - val_loss: 0.1709 - val_accuracy: 0.9698 - val_precision: 0.9858 - val_recall: 0.9534 - val_auc: 0.9940\n",
      "Epoch 22/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1658 - accuracy: 0.9699 - precision: 0.9858 - recall: 0.9535 - auc: 0.9941 - val_loss: 0.1669 - val_accuracy: 0.9700 - val_precision: 0.9858 - val_recall: 0.9537 - val_auc: 0.9941\n",
      "Epoch 23/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1630 - accuracy: 0.9701 - precision: 0.9858 - recall: 0.9538 - auc: 0.9942 - val_loss: 0.1644 - val_accuracy: 0.9702 - val_precision: 0.9859 - val_recall: 0.9540 - val_auc: 0.9942\n",
      "Epoch 24/200\n",
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.1607 - accuracy: 0.9702 - precision: 0.9859 - recall: 0.9541 - auc: 0.9943 - val_loss: 0.1626 - val_accuracy: 0.9703 - val_precision: 0.9859 - val_recall: 0.9543 - val_auc: 0.9943\n",
      "Epoch 25/200\n",
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.1589 - accuracy: 0.9704 - precision: 0.9860 - recall: 0.9544 - auc: 0.9944 - val_loss: 0.1613 - val_accuracy: 0.9705 - val_precision: 0.9860 - val_recall: 0.9545 - val_auc: 0.9944\n",
      "Epoch 26/200\n",
      "99854/99854 [==============================] - 2s 24us/step - loss: 0.1573 - accuracy: 0.9706 - precision: 0.9860 - recall: 0.9546 - auc: 0.9944 - val_loss: 0.1593 - val_accuracy: 0.9706 - val_precision: 0.9861 - val_recall: 0.9548 - val_auc: 0.9945\n",
      "Epoch 27/200\n",
      "99854/99854 [==============================] - 2s 24us/step - loss: 0.1561 - accuracy: 0.9707 - precision: 0.9861 - recall: 0.9549 - auc: 0.9945 - val_loss: 0.1580 - val_accuracy: 0.9708 - val_precision: 0.9861 - val_recall: 0.9550 - val_auc: 0.9945\n",
      "Epoch 28/200\n",
      "99854/99854 [==============================] - 2s 24us/step - loss: 0.1551 - accuracy: 0.9709 - precision: 0.9862 - recall: 0.9551 - auc: 0.9946 - val_loss: 0.1621 - val_accuracy: 0.9709 - val_precision: 0.9862 - val_recall: 0.9552 - val_auc: 0.9946\n",
      "Epoch 29/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1541 - accuracy: 0.9710 - precision: 0.9862 - recall: 0.9553 - auc: 0.9946 - val_loss: 0.1633 - val_accuracy: 0.9711 - val_precision: 0.9862 - val_recall: 0.9554 - val_auc: 0.9947\n",
      "Epoch 30/200\n",
      "99854/99854 [==============================] - 3s 31us/step - loss: 0.1535 - accuracy: 0.9711 - precision: 0.9862 - recall: 0.9555 - auc: 0.9947 - val_loss: 0.1563 - val_accuracy: 0.9712 - val_precision: 0.9863 - val_recall: 0.9557 - val_auc: 0.9947\n",
      "Epoch 31/200\n",
      "99854/99854 [==============================] - 4s 37us/step - loss: 0.1527 - accuracy: 0.9713 - precision: 0.9863 - recall: 0.9558 - auc: 0.9947 - val_loss: 0.1620 - val_accuracy: 0.9713 - val_precision: 0.9863 - val_recall: 0.9559 - val_auc: 0.9948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200\n",
      "99854/99854 [==============================] - 4s 37us/step - loss: 0.1521 - accuracy: 0.9714 - precision: 0.9863 - recall: 0.9560 - auc: 0.9948 - val_loss: 0.1553 - val_accuracy: 0.9714 - val_precision: 0.9863 - val_recall: 0.9561 - val_auc: 0.9948\n",
      "Epoch 33/200\n",
      "99854/99854 [==============================] - 3s 32us/step - loss: 0.1515 - accuracy: 0.9715 - precision: 0.9864 - recall: 0.9562 - auc: 0.9949 - val_loss: 0.1540 - val_accuracy: 0.9715 - val_precision: 0.9864 - val_recall: 0.9563 - val_auc: 0.9949\n",
      "Epoch 34/200\n",
      "99854/99854 [==============================] - 3s 34us/step - loss: 0.1510 - accuracy: 0.9716 - precision: 0.9864 - recall: 0.9564 - auc: 0.9949 - val_loss: 0.1543 - val_accuracy: 0.9716 - val_precision: 0.9864 - val_recall: 0.9564 - val_auc: 0.9949\n",
      "Epoch 35/200\n",
      "99854/99854 [==============================] - 3s 32us/step - loss: 0.1505 - accuracy: 0.9717 - precision: 0.9864 - recall: 0.9565 - auc: 0.9950 - val_loss: 0.1531 - val_accuracy: 0.9717 - val_precision: 0.9865 - val_recall: 0.9566 - val_auc: 0.9950\n",
      "Epoch 36/200\n",
      "99854/99854 [==============================] - 3s 34us/step - loss: 0.1501 - accuracy: 0.9718 - precision: 0.9865 - recall: 0.9567 - auc: 0.9950 - val_loss: 0.1564 - val_accuracy: 0.9718 - val_precision: 0.9865 - val_recall: 0.9568 - val_auc: 0.9950\n",
      "Epoch 37/200\n",
      "99854/99854 [==============================] - 3s 33us/step - loss: 0.1497 - accuracy: 0.9719 - precision: 0.9865 - recall: 0.9568 - auc: 0.9950 - val_loss: 0.1518 - val_accuracy: 0.9719 - val_precision: 0.9866 - val_recall: 0.9569 - val_auc: 0.9951\n",
      "Epoch 38/200\n",
      "99854/99854 [==============================] - 3s 33us/step - loss: 0.1493 - accuracy: 0.9720 - precision: 0.9866 - recall: 0.9570 - auc: 0.9951 - val_loss: 0.1547 - val_accuracy: 0.9720 - val_precision: 0.9866 - val_recall: 0.9571 - val_auc: 0.9951\n",
      "Epoch 39/200\n",
      "99854/99854 [==============================] - 3s 34us/step - loss: 0.1489 - accuracy: 0.9721 - precision: 0.9866 - recall: 0.9571 - auc: 0.9951 - val_loss: 0.1512 - val_accuracy: 0.9721 - val_precision: 0.9866 - val_recall: 0.9572 - val_auc: 0.9951\n",
      "Epoch 40/200\n",
      "99854/99854 [==============================] - 3s 33us/step - loss: 0.1485 - accuracy: 0.9722 - precision: 0.9866 - recall: 0.9573 - auc: 0.9952 - val_loss: 0.1508 - val_accuracy: 0.9722 - val_precision: 0.9867 - val_recall: 0.9574 - val_auc: 0.9952\n",
      "Epoch 41/200\n",
      "99854/99854 [==============================] - 3s 33us/step - loss: 0.1482 - accuracy: 0.9723 - precision: 0.9867 - recall: 0.9574 - auc: 0.9952 - val_loss: 0.1509 - val_accuracy: 0.9723 - val_precision: 0.9867 - val_recall: 0.9575 - val_auc: 0.9952\n",
      "Epoch 42/200\n",
      "99854/99854 [==============================] - 3s 34us/step - loss: 0.1479 - accuracy: 0.9723 - precision: 0.9867 - recall: 0.9576 - auc: 0.9952 - val_loss: 0.1530 - val_accuracy: 0.9724 - val_precision: 0.9867 - val_recall: 0.9577 - val_auc: 0.9952\n",
      "Epoch 43/200\n",
      "99854/99854 [==============================] - 3s 34us/step - loss: 0.1475 - accuracy: 0.9724 - precision: 0.9867 - recall: 0.9577 - auc: 0.9953 - val_loss: 0.1506 - val_accuracy: 0.9725 - val_precision: 0.9867 - val_recall: 0.9578 - val_auc: 0.9953\n",
      "Epoch 44/200\n",
      "99854/99854 [==============================] - 3s 35us/step - loss: 0.1472 - accuracy: 0.9725 - precision: 0.9867 - recall: 0.9579 - auc: 0.9953 - val_loss: 0.1623 - val_accuracy: 0.9725 - val_precision: 0.9868 - val_recall: 0.9579 - val_auc: 0.9953\n",
      "Epoch 45/200\n",
      "99854/99854 [==============================] - 3s 35us/step - loss: 0.1469 - accuracy: 0.9726 - precision: 0.9868 - recall: 0.9580 - auc: 0.9953 - val_loss: 0.1505 - val_accuracy: 0.9726 - val_precision: 0.9868 - val_recall: 0.9581 - val_auc: 0.9953\n",
      "Epoch 46/200\n",
      "99854/99854 [==============================] - 3s 33us/step - loss: 0.1466 - accuracy: 0.9726 - precision: 0.9868 - recall: 0.9581 - auc: 0.9954 - val_loss: 0.1519 - val_accuracy: 0.9727 - val_precision: 0.9868 - val_recall: 0.9582 - val_auc: 0.9954\n",
      "Epoch 47/200\n",
      "99854/99854 [==============================] - 3s 34us/step - loss: 0.1464 - accuracy: 0.9727 - precision: 0.9868 - recall: 0.9582 - auc: 0.9954 - val_loss: 0.1489 - val_accuracy: 0.9728 - val_precision: 0.9868 - val_recall: 0.9583 - val_auc: 0.9954\n",
      "Epoch 48/200\n",
      "99854/99854 [==============================] - 3s 34us/step - loss: 0.1461 - accuracy: 0.9728 - precision: 0.9869 - recall: 0.9583 - auc: 0.9954 - val_loss: 0.1498 - val_accuracy: 0.9728 - val_precision: 0.9869 - val_recall: 0.9584 - val_auc: 0.9954\n",
      "Epoch 49/200\n",
      "99854/99854 [==============================] - 3s 34us/step - loss: 0.1458 - accuracy: 0.9729 - precision: 0.9869 - recall: 0.9584 - auc: 0.9955 - val_loss: 0.1566 - val_accuracy: 0.9729 - val_precision: 0.9869 - val_recall: 0.9585 - val_auc: 0.9955\n",
      "Epoch 50/200\n",
      "99854/99854 [==============================] - 3s 34us/step - loss: 0.1456 - accuracy: 0.9729 - precision: 0.9869 - recall: 0.9586 - auc: 0.9955 - val_loss: 0.1478 - val_accuracy: 0.9730 - val_precision: 0.9869 - val_recall: 0.9586 - val_auc: 0.9955\n",
      "Epoch 51/200\n",
      "99854/99854 [==============================] - 3s 34us/step - loss: 0.1454 - accuracy: 0.9730 - precision: 0.9869 - recall: 0.9587 - auc: 0.9955 - val_loss: 0.1478 - val_accuracy: 0.9730 - val_precision: 0.9869 - val_recall: 0.9587 - val_auc: 0.9955\n",
      "Epoch 52/200\n",
      "99854/99854 [==============================] - 3s 34us/step - loss: 0.1450 - accuracy: 0.9731 - precision: 0.9869 - recall: 0.9588 - auc: 0.9955 - val_loss: 0.1482 - val_accuracy: 0.9731 - val_precision: 0.9870 - val_recall: 0.9588 - val_auc: 0.9955\n",
      "Epoch 53/200\n",
      "99854/99854 [==============================] - 3s 33us/step - loss: 0.1447 - accuracy: 0.9731 - precision: 0.9870 - recall: 0.9589 - auc: 0.9955 - val_loss: 0.1475 - val_accuracy: 0.9732 - val_precision: 0.9870 - val_recall: 0.9589 - val_auc: 0.9956\n",
      "Epoch 54/200\n",
      "99854/99854 [==============================] - 4s 36us/step - loss: 0.1445 - accuracy: 0.9732 - precision: 0.9870 - recall: 0.9590 - auc: 0.9956 - val_loss: 0.1467 - val_accuracy: 0.9732 - val_precision: 0.9870 - val_recall: 0.9590 - val_auc: 0.9956\n",
      "Epoch 55/200\n",
      "99854/99854 [==============================] - 3s 32us/step - loss: 0.1444 - accuracy: 0.9732 - precision: 0.9870 - recall: 0.9591 - auc: 0.9956 - val_loss: 0.1463 - val_accuracy: 0.9733 - val_precision: 0.9870 - val_recall: 0.9591 - val_auc: 0.9956\n",
      "Epoch 56/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1440 - accuracy: 0.9733 - precision: 0.9871 - recall: 0.9592 - auc: 0.9956 - val_loss: 0.1466 - val_accuracy: 0.9733 - val_precision: 0.9871 - val_recall: 0.9592 - val_auc: 0.9956\n",
      "Epoch 57/200\n",
      "99854/99854 [==============================] - 3s 30us/step - loss: 0.1439 - accuracy: 0.9734 - precision: 0.9871 - recall: 0.9593 - auc: 0.9956 - val_loss: 0.1467 - val_accuracy: 0.9734 - val_precision: 0.9871 - val_recall: 0.9593 - val_auc: 0.9957\n",
      "Epoch 58/200\n",
      "99854/99854 [==============================] - 3s 33us/step - loss: 0.1436 - accuracy: 0.9734 - precision: 0.9871 - recall: 0.9594 - auc: 0.9957 - val_loss: 0.1459 - val_accuracy: 0.9734 - val_precision: 0.9871 - val_recall: 0.9594 - val_auc: 0.9957\n",
      "Epoch 59/200\n",
      "99854/99854 [==============================] - 3s 33us/step - loss: 0.1434 - accuracy: 0.9735 - precision: 0.9871 - recall: 0.9595 - auc: 0.9957 - val_loss: 0.1462 - val_accuracy: 0.9735 - val_precision: 0.9871 - val_recall: 0.9595 - val_auc: 0.9957\n",
      "Epoch 60/200\n",
      "99854/99854 [==============================] - 3s 29us/step - loss: 0.1432 - accuracy: 0.9735 - precision: 0.9872 - recall: 0.9596 - auc: 0.9957 - val_loss: 0.1456 - val_accuracy: 0.9736 - val_precision: 0.9872 - val_recall: 0.9596 - val_auc: 0.9957\n",
      "Epoch 61/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1430 - accuracy: 0.9736 - precision: 0.9872 - recall: 0.9596 - auc: 0.9957 - val_loss: 0.1454 - val_accuracy: 0.9736 - val_precision: 0.9872 - val_recall: 0.9597 - val_auc: 0.9957\n",
      "Epoch 62/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1428 - accuracy: 0.9736 - precision: 0.9872 - recall: 0.9597 - auc: 0.9958 - val_loss: 0.1449 - val_accuracy: 0.9737 - val_precision: 0.9872 - val_recall: 0.9598 - val_auc: 0.9958\n",
      "Epoch 63/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1426 - accuracy: 0.9737 - precision: 0.9872 - recall: 0.9598 - auc: 0.9958 - val_loss: 0.1456 - val_accuracy: 0.9737 - val_precision: 0.9872 - val_recall: 0.9599 - val_auc: 0.9958\n",
      "Epoch 64/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1423 - accuracy: 0.9737 - precision: 0.9872 - recall: 0.9599 - auc: 0.9958 - val_loss: 0.1459 - val_accuracy: 0.9738 - val_precision: 0.9872 - val_recall: 0.9599 - val_auc: 0.9958\n",
      "Epoch 65/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1421 - accuracy: 0.9738 - precision: 0.9872 - recall: 0.9600 - auc: 0.9958 - val_loss: 0.1444 - val_accuracy: 0.9738 - val_precision: 0.9873 - val_recall: 0.9600 - val_auc: 0.9958\n",
      "Epoch 66/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1419 - accuracy: 0.9738 - precision: 0.9873 - recall: 0.9601 - auc: 0.9958 - val_loss: 0.1462 - val_accuracy: 0.9739 - val_precision: 0.9873 - val_recall: 0.9601 - val_auc: 0.9958\n",
      "Epoch 67/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1419 - accuracy: 0.9739 - precision: 0.9873 - recall: 0.9601 - auc: 0.9958 - val_loss: 0.1467 - val_accuracy: 0.9739 - val_precision: 0.9873 - val_recall: 0.9602 - val_auc: 0.9959\n",
      "Epoch 68/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1416 - accuracy: 0.9739 - precision: 0.9873 - recall: 0.9602 - auc: 0.9959 - val_loss: 0.1446 - val_accuracy: 0.9740 - val_precision: 0.9873 - val_recall: 0.9603 - val_auc: 0.9959\n",
      "Epoch 69/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1413 - accuracy: 0.9740 - precision: 0.9873 - recall: 0.9603 - auc: 0.9959 - val_loss: 0.1440 - val_accuracy: 0.9740 - val_precision: 0.9873 - val_recall: 0.9604 - val_auc: 0.9959\n",
      "Epoch 70/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1413 - accuracy: 0.9740 - precision: 0.9873 - recall: 0.9604 - auc: 0.9959 - val_loss: 0.1434 - val_accuracy: 0.9741 - val_precision: 0.9873 - val_recall: 0.9604 - val_auc: 0.9959\n",
      "Epoch 71/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1410 - accuracy: 0.9741 - precision: 0.9874 - recall: 0.9605 - auc: 0.9959 - val_loss: 0.1433 - val_accuracy: 0.9741 - val_precision: 0.9874 - val_recall: 0.9605 - val_auc: 0.9959\n",
      "Epoch 72/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1409 - accuracy: 0.9741 - precision: 0.9874 - recall: 0.9605 - auc: 0.9959 - val_loss: 0.1429 - val_accuracy: 0.9741 - val_precision: 0.9874 - val_recall: 0.9606 - val_auc: 0.9959\n",
      "Epoch 73/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1407 - accuracy: 0.9742 - precision: 0.9874 - recall: 0.9606 - auc: 0.9960 - val_loss: 0.1463 - val_accuracy: 0.9742 - val_precision: 0.9874 - val_recall: 0.9606 - val_auc: 0.9960\n",
      "Epoch 74/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1405 - accuracy: 0.9742 - precision: 0.9874 - recall: 0.9607 - auc: 0.9960 - val_loss: 0.1434 - val_accuracy: 0.9742 - val_precision: 0.9874 - val_recall: 0.9607 - val_auc: 0.9960\n",
      "Epoch 75/200\n",
      "99854/99854 [==============================] - 3s 29us/step - loss: 0.1405 - accuracy: 0.9742 - precision: 0.9874 - recall: 0.9607 - auc: 0.9960 - val_loss: 0.1438 - val_accuracy: 0.9743 - val_precision: 0.9874 - val_recall: 0.9608 - val_auc: 0.9960\n",
      "Epoch 76/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1403 - accuracy: 0.9743 - precision: 0.9874 - recall: 0.9608 - auc: 0.9960 - val_loss: 0.1433 - val_accuracy: 0.9743 - val_precision: 0.9875 - val_recall: 0.9608 - val_auc: 0.9960\n",
      "Epoch 77/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1399 - accuracy: 0.9743 - precision: 0.9875 - recall: 0.9609 - auc: 0.9960 - val_loss: 0.1426 - val_accuracy: 0.9744 - val_precision: 0.9875 - val_recall: 0.9609 - val_auc: 0.9960\n",
      "Epoch 78/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1399 - accuracy: 0.9744 - precision: 0.9875 - recall: 0.9609 - auc: 0.9960 - val_loss: 0.1544 - val_accuracy: 0.9744 - val_precision: 0.9875 - val_recall: 0.9610 - val_auc: 0.9960\n",
      "Epoch 79/200\n",
      "99854/99854 [==============================] - 3s 28us/step - loss: 0.1397 - accuracy: 0.9744 - precision: 0.9875 - recall: 0.9610 - auc: 0.9960 - val_loss: 0.1419 - val_accuracy: 0.9744 - val_precision: 0.9875 - val_recall: 0.9610 - val_auc: 0.9960\n",
      "Epoch 80/200\n",
      "99854/99854 [==============================] - 3s 28us/step - loss: 0.1396 - accuracy: 0.9745 - precision: 0.9875 - recall: 0.9611 - auc: 0.9960 - val_loss: 0.1533 - val_accuracy: 0.9745 - val_precision: 0.9875 - val_recall: 0.9611 - val_auc: 0.9960\n",
      "Epoch 81/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1395 - accuracy: 0.9745 - precision: 0.9875 - recall: 0.9612 - auc: 0.9960 - val_loss: 0.1425 - val_accuracy: 0.9745 - val_precision: 0.9875 - val_recall: 0.9612 - val_auc: 0.9961\n",
      "Epoch 82/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1392 - accuracy: 0.9745 - precision: 0.9875 - recall: 0.9612 - auc: 0.9961 - val_loss: 0.1494 - val_accuracy: 0.9745 - val_precision: 0.9875 - val_recall: 0.9612 - val_auc: 0.9961\n",
      "Epoch 83/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1392 - accuracy: 0.9746 - precision: 0.9875 - recall: 0.9613 - auc: 0.9961 - val_loss: 0.1416 - val_accuracy: 0.9746 - val_precision: 0.9875 - val_recall: 0.9613 - val_auc: 0.9961\n",
      "Epoch 84/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1389 - accuracy: 0.9746 - precision: 0.9875 - recall: 0.9613 - auc: 0.9961 - val_loss: 0.1420 - val_accuracy: 0.9746 - val_precision: 0.9875 - val_recall: 0.9614 - val_auc: 0.9961\n",
      "Epoch 85/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1388 - accuracy: 0.9746 - precision: 0.9875 - recall: 0.9614 - auc: 0.9961 - val_loss: 0.1426 - val_accuracy: 0.9747 - val_precision: 0.9875 - val_recall: 0.9614 - val_auc: 0.9961\n",
      "Epoch 86/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1387 - accuracy: 0.9747 - precision: 0.9875 - recall: 0.9615 - auc: 0.9961 - val_loss: 0.1408 - val_accuracy: 0.9747 - val_precision: 0.9876 - val_recall: 0.9615 - val_auc: 0.9961\n",
      "Epoch 87/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1385 - accuracy: 0.9747 - precision: 0.9876 - recall: 0.9615 - auc: 0.9961 - val_loss: 0.1415 - val_accuracy: 0.9747 - val_precision: 0.9876 - val_recall: 0.9615 - val_auc: 0.9961\n",
      "Epoch 88/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1383 - accuracy: 0.9747 - precision: 0.9876 - recall: 0.9616 - auc: 0.9961 - val_loss: 0.1439 - val_accuracy: 0.9748 - val_precision: 0.9876 - val_recall: 0.9616 - val_auc: 0.9961\n",
      "Epoch 89/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1384 - accuracy: 0.9748 - precision: 0.9876 - recall: 0.9616 - auc: 0.9962 - val_loss: 0.1421 - val_accuracy: 0.9748 - val_precision: 0.9876 - val_recall: 0.9617 - val_auc: 0.9962\n",
      "Epoch 90/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1381 - accuracy: 0.9748 - precision: 0.9876 - recall: 0.9617 - auc: 0.9962 - val_loss: 0.1415 - val_accuracy: 0.9748 - val_precision: 0.9876 - val_recall: 0.9617 - val_auc: 0.9962\n",
      "Epoch 91/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1379 - accuracy: 0.9748 - precision: 0.9876 - recall: 0.9617 - auc: 0.9962 - val_loss: 0.1431 - val_accuracy: 0.9749 - val_precision: 0.9876 - val_recall: 0.9618 - val_auc: 0.9962\n",
      "Epoch 92/200\n",
      "99854/99854 [==============================] - 3s 28us/step - loss: 0.1377 - accuracy: 0.9749 - precision: 0.9876 - recall: 0.9618 - auc: 0.9962 - val_loss: 0.1418 - val_accuracy: 0.9749 - val_precision: 0.9876 - val_recall: 0.9618 - val_auc: 0.9962\n",
      "Epoch 93/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1378 - accuracy: 0.9749 - precision: 0.9877 - recall: 0.9618 - auc: 0.9962 - val_loss: 0.1407 - val_accuracy: 0.9749 - val_precision: 0.9877 - val_recall: 0.9619 - val_auc: 0.9962\n",
      "Epoch 94/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1374 - accuracy: 0.9750 - precision: 0.9877 - recall: 0.9619 - auc: 0.9962 - val_loss: 0.1407 - val_accuracy: 0.9750 - val_precision: 0.9877 - val_recall: 0.9619 - val_auc: 0.9962\n",
      "Epoch 95/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1375 - accuracy: 0.9750 - precision: 0.9877 - recall: 0.9620 - auc: 0.9962 - val_loss: 0.1430 - val_accuracy: 0.9750 - val_precision: 0.9877 - val_recall: 0.9620 - val_auc: 0.9962\n",
      "Epoch 96/200\n",
      "99854/99854 [==============================] - 3s 28us/step - loss: 0.1373 - accuracy: 0.9750 - precision: 0.9877 - recall: 0.9620 - auc: 0.9962 - val_loss: 0.1404 - val_accuracy: 0.9750 - val_precision: 0.9877 - val_recall: 0.9620 - val_auc: 0.9962\n",
      "Epoch 97/200\n",
      "99854/99854 [==============================] - 3s 28us/step - loss: 0.1372 - accuracy: 0.9750 - precision: 0.9877 - recall: 0.9620 - auc: 0.9962 - val_loss: 0.1391 - val_accuracy: 0.9751 - val_precision: 0.9877 - val_recall: 0.9621 - val_auc: 0.9962\n",
      "Epoch 98/200\n",
      "99854/99854 [==============================] - 3s 28us/step - loss: 0.1371 - accuracy: 0.9751 - precision: 0.9877 - recall: 0.9621 - auc: 0.9962 - val_loss: 0.1432 - val_accuracy: 0.9751 - val_precision: 0.9877 - val_recall: 0.9621 - val_auc: 0.9962\n",
      "Epoch 99/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1369 - accuracy: 0.9751 - precision: 0.9877 - recall: 0.9621 - auc: 0.9963 - val_loss: 0.1390 - val_accuracy: 0.9751 - val_precision: 0.9877 - val_recall: 0.9622 - val_auc: 0.9963\n",
      "Epoch 100/200\n",
      "99854/99854 [==============================] - 3s 28us/step - loss: 0.1368 - accuracy: 0.9751 - precision: 0.9877 - recall: 0.9622 - auc: 0.9963 - val_loss: 0.1415 - val_accuracy: 0.9751 - val_precision: 0.9878 - val_recall: 0.9622 - val_auc: 0.9963\n",
      "Epoch 101/200\n",
      "99854/99854 [==============================] - 3s 29us/step - loss: 0.1366 - accuracy: 0.9752 - precision: 0.9877 - recall: 0.9623 - auc: 0.9963 - val_loss: 0.1389 - val_accuracy: 0.9752 - val_precision: 0.9878 - val_recall: 0.9623 - val_auc: 0.9963\n",
      "Epoch 102/200\n",
      "99854/99854 [==============================] - 3s 28us/step - loss: 0.1366 - accuracy: 0.9752 - precision: 0.9878 - recall: 0.9623 - auc: 0.9963 - val_loss: 0.1385 - val_accuracy: 0.9752 - val_precision: 0.9878 - val_recall: 0.9623 - val_auc: 0.9963\n",
      "Epoch 103/200\n",
      "99854/99854 [==============================] - 3s 29us/step - loss: 0.1364 - accuracy: 0.9752 - precision: 0.9878 - recall: 0.9623 - auc: 0.9963 - val_loss: 0.1393 - val_accuracy: 0.9752 - val_precision: 0.9878 - val_recall: 0.9624 - val_auc: 0.9963\n",
      "Epoch 104/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1363 - accuracy: 0.9753 - precision: 0.9878 - recall: 0.9624 - auc: 0.9963 - val_loss: 0.1383 - val_accuracy: 0.9753 - val_precision: 0.9878 - val_recall: 0.9624 - val_auc: 0.9963\n",
      "Epoch 105/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1362 - accuracy: 0.9753 - precision: 0.9878 - recall: 0.9624 - auc: 0.9963 - val_loss: 0.1388 - val_accuracy: 0.9753 - val_precision: 0.9878 - val_recall: 0.9625 - val_auc: 0.9963\n",
      "Epoch 106/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1361 - accuracy: 0.9753 - precision: 0.9878 - recall: 0.9625 - auc: 0.9963 - val_loss: 0.1475 - val_accuracy: 0.9753 - val_precision: 0.9878 - val_recall: 0.9625 - val_auc: 0.9963\n",
      "Epoch 107/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1358 - accuracy: 0.9753 - precision: 0.9878 - recall: 0.9625 - auc: 0.9963 - val_loss: 0.1419 - val_accuracy: 0.9753 - val_precision: 0.9878 - val_recall: 0.9626 - val_auc: 0.9963\n",
      "Epoch 108/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1358 - accuracy: 0.9754 - precision: 0.9878 - recall: 0.9626 - auc: 0.9963 - val_loss: 0.1439 - val_accuracy: 0.9754 - val_precision: 0.9878 - val_recall: 0.9626 - val_auc: 0.9963\n",
      "Epoch 109/200\n",
      "99854/99854 [==============================] - 3s 28us/step - loss: 0.1357 - accuracy: 0.9754 - precision: 0.9879 - recall: 0.9626 - auc: 0.9963 - val_loss: 0.1378 - val_accuracy: 0.9754 - val_precision: 0.9879 - val_recall: 0.9626 - val_auc: 0.9963\n",
      "Epoch 110/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1356 - accuracy: 0.9754 - precision: 0.9879 - recall: 0.9626 - auc: 0.9963 - val_loss: 0.1706 - val_accuracy: 0.9754 - val_precision: 0.9879 - val_recall: 0.9627 - val_auc: 0.9964\n",
      "Epoch 111/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1355 - accuracy: 0.9754 - precision: 0.9879 - recall: 0.9627 - auc: 0.9964 - val_loss: 0.1377 - val_accuracy: 0.9754 - val_precision: 0.9879 - val_recall: 0.9627 - val_auc: 0.9964\n",
      "Epoch 112/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1353 - accuracy: 0.9755 - precision: 0.9879 - recall: 0.9628 - auc: 0.9964 - val_loss: 0.1374 - val_accuracy: 0.9755 - val_precision: 0.9879 - val_recall: 0.9628 - val_auc: 0.9964\n",
      "Epoch 113/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1354 - accuracy: 0.9755 - precision: 0.9879 - recall: 0.9628 - auc: 0.9964 - val_loss: 0.1374 - val_accuracy: 0.9755 - val_precision: 0.9879 - val_recall: 0.9628 - val_auc: 0.9964\n",
      "Epoch 114/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1352 - accuracy: 0.9755 - precision: 0.9879 - recall: 0.9628 - auc: 0.9964 - val_loss: 0.1389 - val_accuracy: 0.9755 - val_precision: 0.9879 - val_recall: 0.9629 - val_auc: 0.9964\n",
      "Epoch 115/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1350 - accuracy: 0.9755 - precision: 0.9879 - recall: 0.9629 - auc: 0.9964 - val_loss: 0.1371 - val_accuracy: 0.9756 - val_precision: 0.9879 - val_recall: 0.9629 - val_auc: 0.9964\n",
      "Epoch 116/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1349 - accuracy: 0.9756 - precision: 0.9879 - recall: 0.9629 - auc: 0.9964 - val_loss: 0.1374 - val_accuracy: 0.9756 - val_precision: 0.9879 - val_recall: 0.9629 - val_auc: 0.9964\n",
      "Epoch 117/200\n",
      "99854/99854 [==============================] - 3s 28us/step - loss: 0.1348 - accuracy: 0.9756 - precision: 0.9879 - recall: 0.9630 - auc: 0.9964 - val_loss: 0.1369 - val_accuracy: 0.9756 - val_precision: 0.9879 - val_recall: 0.9630 - val_auc: 0.9964\n",
      "Epoch 118/200\n",
      "99854/99854 [==============================] - 3s 28us/step - loss: 0.1348 - accuracy: 0.9756 - precision: 0.9879 - recall: 0.9630 - auc: 0.9964 - val_loss: 0.1372 - val_accuracy: 0.9756 - val_precision: 0.9879 - val_recall: 0.9630 - val_auc: 0.9964\n",
      "Epoch 119/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1347 - accuracy: 0.9756 - precision: 0.9879 - recall: 0.9630 - auc: 0.9964 - val_loss: 0.1376 - val_accuracy: 0.9756 - val_precision: 0.9879 - val_recall: 0.9631 - val_auc: 0.9964\n",
      "Epoch 120/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1346 - accuracy: 0.9757 - precision: 0.9880 - recall: 0.9631 - auc: 0.9964 - val_loss: 0.1364 - val_accuracy: 0.9757 - val_precision: 0.9879 - val_recall: 0.9631 - val_auc: 0.9964\n",
      "Epoch 121/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1343 - accuracy: 0.9757 - precision: 0.9880 - recall: 0.9631 - auc: 0.9964 - val_loss: 0.1482 - val_accuracy: 0.9757 - val_precision: 0.9880 - val_recall: 0.9631 - val_auc: 0.9964\n",
      "Epoch 122/200\n",
      "99854/99854 [==============================] - 3s 29us/step - loss: 0.1345 - accuracy: 0.9757 - precision: 0.9880 - recall: 0.9631 - auc: 0.9964 - val_loss: 0.1362 - val_accuracy: 0.9757 - val_precision: 0.9880 - val_recall: 0.9632 - val_auc: 0.9964\n",
      "Epoch 123/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1342 - accuracy: 0.9757 - precision: 0.9880 - recall: 0.9632 - auc: 0.9965 - val_loss: 0.1364 - val_accuracy: 0.9757 - val_precision: 0.9880 - val_recall: 0.9632 - val_auc: 0.9964\n",
      "Epoch 124/200\n",
      "99854/99854 [==============================] - 3s 29us/step - loss: 0.1342 - accuracy: 0.9757 - precision: 0.9880 - recall: 0.9632 - auc: 0.9965 - val_loss: 0.1401 - val_accuracy: 0.9758 - val_precision: 0.9880 - val_recall: 0.9632 - val_auc: 0.9965\n",
      "Epoch 125/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1341 - accuracy: 0.9758 - precision: 0.9880 - recall: 0.9632 - auc: 0.9965 - val_loss: 0.1390 - val_accuracy: 0.9758 - val_precision: 0.9880 - val_recall: 0.9633 - val_auc: 0.9965\n",
      "Epoch 126/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1341 - accuracy: 0.9758 - precision: 0.9880 - recall: 0.9633 - auc: 0.9965 - val_loss: 0.1421 - val_accuracy: 0.9758 - val_precision: 0.9880 - val_recall: 0.9633 - val_auc: 0.9965\n",
      "Epoch 127/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1339 - accuracy: 0.9758 - precision: 0.9880 - recall: 0.9633 - auc: 0.9965 - val_loss: 0.1359 - val_accuracy: 0.9758 - val_precision: 0.9880 - val_recall: 0.9633 - val_auc: 0.9965\n",
      "Epoch 128/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1336 - accuracy: 0.9758 - precision: 0.9880 - recall: 0.9633 - auc: 0.9965 - val_loss: 0.1456 - val_accuracy: 0.9758 - val_precision: 0.9880 - val_recall: 0.9634 - val_auc: 0.9965\n",
      "Epoch 129/200\n",
      "99854/99854 [==============================] - 3s 29us/step - loss: 0.1337 - accuracy: 0.9759 - precision: 0.9880 - recall: 0.9634 - auc: 0.9965 - val_loss: 0.1357 - val_accuracy: 0.9759 - val_precision: 0.9880 - val_recall: 0.9634 - val_auc: 0.9965\n",
      "Epoch 130/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1336 - accuracy: 0.9759 - precision: 0.9881 - recall: 0.9634 - auc: 0.9965 - val_loss: 0.1464 - val_accuracy: 0.9759 - val_precision: 0.9881 - val_recall: 0.9634 - val_auc: 0.9965\n",
      "Epoch 131/200\n",
      "99854/99854 [==============================] - ETA: 0s - loss: 0.1333 - accuracy: 0.9759 - precision: 0.9880 - recall: 0.9634 - auc: 0.996 - 3s 27us/step - loss: 0.1333 - accuracy: 0.9759 - precision: 0.9880 - recall: 0.9634 - auc: 0.9965 - val_loss: 0.1360 - val_accuracy: 0.9759 - val_precision: 0.9881 - val_recall: 0.9635 - val_auc: 0.9965\n",
      "Epoch 132/200\n",
      "99854/99854 [==============================] - 3s 28us/step - loss: 0.1334 - accuracy: 0.9759 - precision: 0.9881 - recall: 0.9635 - auc: 0.9965 - val_loss: 0.1473 - val_accuracy: 0.9759 - val_precision: 0.9881 - val_recall: 0.9635 - val_auc: 0.9965\n",
      "Epoch 133/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1334 - accuracy: 0.9759 - precision: 0.9881 - recall: 0.9635 - auc: 0.9965 - val_loss: 0.1370 - val_accuracy: 0.9760 - val_precision: 0.9881 - val_recall: 0.9635 - val_auc: 0.9965\n",
      "Epoch 134/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1332 - accuracy: 0.9760 - precision: 0.9881 - recall: 0.9636 - auc: 0.9965 - val_loss: 0.1361 - val_accuracy: 0.9760 - val_precision: 0.9881 - val_recall: 0.9636 - val_auc: 0.9965\n",
      "Epoch 135/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1331 - accuracy: 0.9760 - precision: 0.9881 - recall: 0.9636 - auc: 0.9965 - val_loss: 0.1351 - val_accuracy: 0.9760 - val_precision: 0.9881 - val_recall: 0.9636 - val_auc: 0.9965\n",
      "Epoch 136/200\n",
      "99854/99854 [==============================] - 3s 29us/step - loss: 0.1329 - accuracy: 0.9760 - precision: 0.9881 - recall: 0.9636 - auc: 0.9965 - val_loss: 0.1366 - val_accuracy: 0.9760 - val_precision: 0.9881 - val_recall: 0.9636 - val_auc: 0.9965\n",
      "Epoch 137/200\n",
      "99854/99854 [==============================] - 3s 28us/step - loss: 0.1329 - accuracy: 0.9760 - precision: 0.9881 - recall: 0.9637 - auc: 0.9965 - val_loss: 0.1360 - val_accuracy: 0.9760 - val_precision: 0.9881 - val_recall: 0.9637 - val_auc: 0.9965\n",
      "Epoch 138/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1327 - accuracy: 0.9761 - precision: 0.9881 - recall: 0.9637 - auc: 0.9965 - val_loss: 0.1361 - val_accuracy: 0.9761 - val_precision: 0.9881 - val_recall: 0.9637 - val_auc: 0.9965\n",
      "Epoch 139/200\n",
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.1327 - accuracy: 0.9761 - precision: 0.9881 - recall: 0.9637 - auc: 0.9965 - val_loss: 0.1463 - val_accuracy: 0.9761 - val_precision: 0.9881 - val_recall: 0.9637 - val_auc: 0.9965\n",
      "Epoch 140/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1326 - accuracy: 0.9761 - precision: 0.9881 - recall: 0.9638 - auc: 0.9966 - val_loss: 0.1365 - val_accuracy: 0.9761 - val_precision: 0.9881 - val_recall: 0.9638 - val_auc: 0.9966\n",
      "Epoch 141/200\n",
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.1325 - accuracy: 0.9761 - precision: 0.9881 - recall: 0.9638 - auc: 0.9966 - val_loss: 0.1345 - val_accuracy: 0.9761 - val_precision: 0.9881 - val_recall: 0.9638 - val_auc: 0.9966\n",
      "Epoch 142/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1325 - accuracy: 0.9761 - precision: 0.9882 - recall: 0.9638 - auc: 0.9966 - val_loss: 0.1364 - val_accuracy: 0.9761 - val_precision: 0.9882 - val_recall: 0.9638 - val_auc: 0.9966\n",
      "Epoch 143/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1322 - accuracy: 0.9762 - precision: 0.9882 - recall: 0.9639 - auc: 0.9966 - val_loss: 0.1346 - val_accuracy: 0.9762 - val_precision: 0.9882 - val_recall: 0.9639 - val_auc: 0.9966\n",
      "Epoch 144/200\n",
      "99854/99854 [==============================] - 3s 28us/step - loss: 0.1322 - accuracy: 0.9762 - precision: 0.9882 - recall: 0.9639 - auc: 0.9966 - val_loss: 0.1379 - val_accuracy: 0.9762 - val_precision: 0.9882 - val_recall: 0.9639 - val_auc: 0.9966\n",
      "Epoch 145/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1321 - accuracy: 0.9762 - precision: 0.9882 - recall: 0.9639 - auc: 0.9966 - val_loss: 0.1613 - val_accuracy: 0.9762 - val_precision: 0.9882 - val_recall: 0.9639 - val_auc: 0.9966\n",
      "Epoch 146/200\n",
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.1321 - accuracy: 0.9762 - precision: 0.9882 - recall: 0.9640 - auc: 0.9966 - val_loss: 0.1342 - val_accuracy: 0.9762 - val_precision: 0.9882 - val_recall: 0.9640 - val_auc: 0.9966\n",
      "Epoch 147/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1320 - accuracy: 0.9762 - precision: 0.9882 - recall: 0.9640 - auc: 0.9966 - val_loss: 0.1343 - val_accuracy: 0.9762 - val_precision: 0.9882 - val_recall: 0.9640 - val_auc: 0.9966\n",
      "Epoch 148/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1320 - accuracy: 0.9763 - precision: 0.9882 - recall: 0.9640 - auc: 0.9966 - val_loss: 0.1354 - val_accuracy: 0.9763 - val_precision: 0.9882 - val_recall: 0.9640 - val_auc: 0.9966\n",
      "Epoch 149/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1318 - accuracy: 0.9763 - precision: 0.9882 - recall: 0.9640 - auc: 0.9966 - val_loss: 0.1437 - val_accuracy: 0.9763 - val_precision: 0.9882 - val_recall: 0.9641 - val_auc: 0.9966\n",
      "Epoch 150/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1318 - accuracy: 0.9763 - precision: 0.9882 - recall: 0.9641 - auc: 0.9966 - val_loss: 0.1356 - val_accuracy: 0.9763 - val_precision: 0.9882 - val_recall: 0.9641 - val_auc: 0.9966\n",
      "Epoch 151/200\n",
      "99854/99854 [==============================] - 3s 28us/step - loss: 0.1316 - accuracy: 0.9763 - precision: 0.9882 - recall: 0.9641 - auc: 0.9966 - val_loss: 0.1375 - val_accuracy: 0.9763 - val_precision: 0.9882 - val_recall: 0.9641 - val_auc: 0.9966\n",
      "Epoch 152/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1316 - accuracy: 0.9763 - precision: 0.9882 - recall: 0.9641 - auc: 0.9966 - val_loss: 0.1363 - val_accuracy: 0.9763 - val_precision: 0.9882 - val_recall: 0.9642 - val_auc: 0.9966\n",
      "Epoch 153/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1315 - accuracy: 0.9764 - precision: 0.9882 - recall: 0.9642 - auc: 0.9966 - val_loss: 0.1401 - val_accuracy: 0.9764 - val_precision: 0.9882 - val_recall: 0.9642 - val_auc: 0.9966\n",
      "Epoch 154/200\n",
      "99854/99854 [==============================] - 3s 28us/step - loss: 0.1314 - accuracy: 0.9764 - precision: 0.9883 - recall: 0.9642 - auc: 0.9966 - val_loss: 0.1376 - val_accuracy: 0.9764 - val_precision: 0.9883 - val_recall: 0.9642 - val_auc: 0.9966\n",
      "Epoch 155/200\n",
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.1314 - accuracy: 0.9764 - precision: 0.9883 - recall: 0.9642 - auc: 0.9966 - val_loss: 0.1337 - val_accuracy: 0.9764 - val_precision: 0.9883 - val_recall: 0.9642 - val_auc: 0.9966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/200\n",
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.1312 - accuracy: 0.9764 - precision: 0.9883 - recall: 0.9642 - auc: 0.9966 - val_loss: 0.1446 - val_accuracy: 0.9764 - val_precision: 0.9883 - val_recall: 0.9643 - val_auc: 0.9966\n",
      "Epoch 157/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1313 - accuracy: 0.9764 - precision: 0.9883 - recall: 0.9643 - auc: 0.9966 - val_loss: 0.1338 - val_accuracy: 0.9764 - val_precision: 0.9883 - val_recall: 0.9643 - val_auc: 0.9966\n",
      "Epoch 158/200\n",
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.1311 - accuracy: 0.9764 - precision: 0.9883 - recall: 0.9643 - auc: 0.9966 - val_loss: 0.1338 - val_accuracy: 0.9764 - val_precision: 0.9883 - val_recall: 0.9643 - val_auc: 0.9967\n",
      "Epoch 159/200\n",
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.1310 - accuracy: 0.9764 - precision: 0.9883 - recall: 0.9643 - auc: 0.9966 - val_loss: 0.1564 - val_accuracy: 0.9765 - val_precision: 0.9883 - val_recall: 0.9644 - val_auc: 0.9967\n",
      "Epoch 160/200\n",
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.1310 - accuracy: 0.9765 - precision: 0.9883 - recall: 0.9644 - auc: 0.9966 - val_loss: 0.1471 - val_accuracy: 0.9765 - val_precision: 0.9883 - val_recall: 0.9644 - val_auc: 0.9967\n",
      "Epoch 161/200\n",
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.1309 - accuracy: 0.9765 - precision: 0.9883 - recall: 0.9644 - auc: 0.9967 - val_loss: 0.1325 - val_accuracy: 0.9765 - val_precision: 0.9883 - val_recall: 0.9644 - val_auc: 0.9967\n",
      "Epoch 162/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1307 - accuracy: 0.9765 - precision: 0.9883 - recall: 0.9644 - auc: 0.9967 - val_loss: 0.1361 - val_accuracy: 0.9765 - val_precision: 0.9883 - val_recall: 0.9644 - val_auc: 0.9967\n",
      "Epoch 163/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 0.1309 - accuracy: 0.9765 - precision: 0.9883 - recall: 0.9645 - auc: 0.9967 - val_loss: 0.1330 - val_accuracy: 0.9765 - val_precision: 0.9883 - val_recall: 0.9645 - val_auc: 0.9967\n",
      "Epoch 164/200\n",
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.1306 - accuracy: 0.9765 - precision: 0.9883 - recall: 0.9645 - auc: 0.9967 - val_loss: 0.1349 - val_accuracy: 0.9765 - val_precision: 0.9883 - val_recall: 0.9645 - val_auc: 0.9967\n",
      "Epoch 165/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1306 - accuracy: 0.9766 - precision: 0.9883 - recall: 0.9645 - auc: 0.9967 - val_loss: 0.1330 - val_accuracy: 0.9766 - val_precision: 0.9883 - val_recall: 0.9645 - val_auc: 0.9967\n",
      "Epoch 166/200\n",
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.1306 - accuracy: 0.9766 - precision: 0.9883 - recall: 0.9645 - auc: 0.9967 - val_loss: 0.1432 - val_accuracy: 0.9766 - val_precision: 0.9883 - val_recall: 0.9645 - val_auc: 0.9967\n",
      "Epoch 167/200\n",
      "99854/99854 [==============================] - 2s 24us/step - loss: 0.1305 - accuracy: 0.9766 - precision: 0.9883 - recall: 0.9646 - auc: 0.9967 - val_loss: 0.1330 - val_accuracy: 0.9766 - val_precision: 0.9883 - val_recall: 0.9646 - val_auc: 0.9967\n",
      "Epoch 168/200\n",
      "99854/99854 [==============================] - 2s 24us/step - loss: 0.1304 - accuracy: 0.9766 - precision: 0.9883 - recall: 0.9646 - auc: 0.9967 - val_loss: 0.1322 - val_accuracy: 0.9766 - val_precision: 0.9883 - val_recall: 0.9646 - val_auc: 0.9967\n",
      "Epoch 169/200\n",
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.1303 - accuracy: 0.9766 - precision: 0.9883 - recall: 0.9646 - auc: 0.9967 - val_loss: 0.1330 - val_accuracy: 0.9766 - val_precision: 0.9883 - val_recall: 0.9646 - val_auc: 0.9967\n",
      "Epoch 170/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1302 - accuracy: 0.9766 - precision: 0.9883 - recall: 0.9646 - auc: 0.9967 - val_loss: 0.1519 - val_accuracy: 0.9766 - val_precision: 0.9883 - val_recall: 0.9647 - val_auc: 0.9967\n",
      "Epoch 171/200\n",
      "99854/99854 [==============================] - 3s 28us/step - loss: 0.1301 - accuracy: 0.9767 - precision: 0.9883 - recall: 0.9647 - auc: 0.9967 - val_loss: 0.1321 - val_accuracy: 0.9767 - val_precision: 0.9883 - val_recall: 0.9647 - val_auc: 0.9967\n",
      "Epoch 172/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1300 - accuracy: 0.9767 - precision: 0.9883 - recall: 0.9647 - auc: 0.9967 - val_loss: 0.1321 - val_accuracy: 0.9767 - val_precision: 0.9883 - val_recall: 0.9647 - val_auc: 0.9967\n",
      "Epoch 173/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1300 - accuracy: 0.9767 - precision: 0.9883 - recall: 0.9647 - auc: 0.9967 - val_loss: 0.1341 - val_accuracy: 0.9767 - val_precision: 0.9884 - val_recall: 0.9647 - val_auc: 0.9967\n",
      "Epoch 174/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 0.1301 - accuracy: 0.9767 - precision: 0.9884 - recall: 0.9648 - auc: 0.9967 - val_loss: 0.1318 - val_accuracy: 0.9767 - val_precision: 0.9884 - val_recall: 0.9648 - val_auc: 0.9967\n",
      "Epoch 175/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1298 - accuracy: 0.9767 - precision: 0.9884 - recall: 0.9648 - auc: 0.9967 - val_loss: 0.1315 - val_accuracy: 0.9767 - val_precision: 0.9884 - val_recall: 0.9648 - val_auc: 0.9967\n",
      "Epoch 176/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 0.1297 - accuracy: 0.9767 - precision: 0.9884 - recall: 0.9648 - auc: 0.9967 - val_loss: 0.1328 - val_accuracy: 0.9767 - val_precision: 0.9884 - val_recall: 0.9648 - val_auc: 0.9967\n",
      "Epoch 177/200\n",
      "99854/99854 [==============================] - 2s 24us/step - loss: 0.1297 - accuracy: 0.9767 - precision: 0.9884 - recall: 0.9648 - auc: 0.9967 - val_loss: 0.1331 - val_accuracy: 0.9768 - val_precision: 0.9884 - val_recall: 0.9648 - val_auc: 0.9967\n",
      "Epoch 178/200\n",
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.1296 - accuracy: 0.9768 - precision: 0.9884 - recall: 0.9648 - auc: 0.9967 - val_loss: 0.1366 - val_accuracy: 0.9768 - val_precision: 0.9884 - val_recall: 0.9649 - val_auc: 0.9967\n",
      "Epoch 179/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 0.1297 - accuracy: 0.9768 - precision: 0.9884 - recall: 0.9649 - auc: 0.9967 - val_loss: 0.1331 - val_accuracy: 0.9768 - val_precision: 0.9884 - val_recall: 0.9649 - val_auc: 0.9967\n",
      "Epoch 180/200\n",
      "99854/99854 [==============================] - 2s 24us/step - loss: 0.1296 - accuracy: 0.9768 - precision: 0.9884 - recall: 0.9649 - auc: 0.9967 - val_loss: 0.1329 - val_accuracy: 0.9768 - val_precision: 0.9884 - val_recall: 0.9649 - val_auc: 0.9967\n",
      "Epoch 181/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 0.1295 - accuracy: 0.9768 - precision: 0.9884 - recall: 0.9649 - auc: 0.9968 - val_loss: 0.1363 - val_accuracy: 0.9768 - val_precision: 0.9884 - val_recall: 0.9649 - val_auc: 0.9968\n",
      "Epoch 182/200\n",
      "99854/99854 [==============================] - 2s 24us/step - loss: 0.1294 - accuracy: 0.9768 - precision: 0.9884 - recall: 0.9649 - auc: 0.9968 - val_loss: 0.1313 - val_accuracy: 0.9768 - val_precision: 0.9884 - val_recall: 0.9649 - val_auc: 0.9968\n",
      "Epoch 183/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1293 - accuracy: 0.9768 - precision: 0.9884 - recall: 0.9650 - auc: 0.9968 - val_loss: 0.1334 - val_accuracy: 0.9768 - val_precision: 0.9884 - val_recall: 0.9650 - val_auc: 0.9968\n",
      "Epoch 184/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1293 - accuracy: 0.9769 - precision: 0.9884 - recall: 0.9650 - auc: 0.9968 - val_loss: 0.1317 - val_accuracy: 0.9769 - val_precision: 0.9884 - val_recall: 0.9650 - val_auc: 0.9968\n",
      "Epoch 185/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1293 - accuracy: 0.9769 - precision: 0.9884 - recall: 0.9650 - auc: 0.9968 - val_loss: 0.1343 - val_accuracy: 0.9769 - val_precision: 0.9884 - val_recall: 0.9650 - val_auc: 0.9968\n",
      "Epoch 186/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1291 - accuracy: 0.9769 - precision: 0.9884 - recall: 0.9650 - auc: 0.9968 - val_loss: 0.1386 - val_accuracy: 0.9769 - val_precision: 0.9884 - val_recall: 0.9650 - val_auc: 0.9968\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.1291 - accuracy: 0.9769 - precision: 0.9885 - recall: 0.9650 - auc: 0.9968 - val_loss: 0.1407 - val_accuracy: 0.9769 - val_precision: 0.9885 - val_recall: 0.9651 - val_auc: 0.9968\n",
      "Epoch 188/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1291 - accuracy: 0.9769 - precision: 0.9885 - recall: 0.9651 - auc: 0.9968 - val_loss: 0.1331 - val_accuracy: 0.9769 - val_precision: 0.9885 - val_recall: 0.9651 - val_auc: 0.9968\n",
      "Epoch 189/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1291 - accuracy: 0.9769 - precision: 0.9885 - recall: 0.9651 - auc: 0.9968 - val_loss: 0.1330 - val_accuracy: 0.9769 - val_precision: 0.9885 - val_recall: 0.9651 - val_auc: 0.9968\n",
      "Epoch 190/200\n",
      "99854/99854 [==============================] - 2s 25us/step - loss: 0.1289 - accuracy: 0.9769 - precision: 0.9885 - recall: 0.9651 - auc: 0.9968 - val_loss: 0.1327 - val_accuracy: 0.9769 - val_precision: 0.9885 - val_recall: 0.9651 - val_auc: 0.9968\n",
      "Epoch 191/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1290 - accuracy: 0.9769 - precision: 0.9885 - recall: 0.9651 - auc: 0.9968 - val_loss: 0.1359 - val_accuracy: 0.9770 - val_precision: 0.9885 - val_recall: 0.9651 - val_auc: 0.9968\n",
      "Epoch 192/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1289 - accuracy: 0.9770 - precision: 0.9885 - recall: 0.9651 - auc: 0.9968 - val_loss: 0.1343 - val_accuracy: 0.9770 - val_precision: 0.9885 - val_recall: 0.9652 - val_auc: 0.9968\n",
      "Epoch 193/200\n",
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.1287 - accuracy: 0.9770 - precision: 0.9885 - recall: 0.9651 - auc: 0.9968 - val_loss: 0.1317 - val_accuracy: 0.9770 - val_precision: 0.9885 - val_recall: 0.9652 - val_auc: 0.9968\n",
      "Epoch 194/200\n",
      "99854/99854 [==============================] - 3s 26us/step - loss: 0.1289 - accuracy: 0.9770 - precision: 0.9885 - recall: 0.9652 - auc: 0.9968 - val_loss: 0.1316 - val_accuracy: 0.9770 - val_precision: 0.9885 - val_recall: 0.9652 - val_auc: 0.9968\n",
      "Epoch 195/200\n",
      "99854/99854 [==============================] - 3s 27us/step - loss: 0.1285 - accuracy: 0.9770 - precision: 0.9885 - recall: 0.9652 - auc: 0.9968 - val_loss: 0.1306 - val_accuracy: 0.9770 - val_precision: 0.9885 - val_recall: 0.9652 - val_auc: 0.9968\n",
      "Epoch 196/200\n",
      "99854/99854 [==============================] - 3s 25us/step - loss: 0.1285 - accuracy: 0.9770 - precision: 0.9885 - recall: 0.9652 - auc: 0.9968 - val_loss: 0.1327 - val_accuracy: 0.9770 - val_precision: 0.9885 - val_recall: 0.9652 - val_auc: 0.9968\n",
      "Epoch 197/200\n",
      "99854/99854 [==============================] - 2s 24us/step - loss: 0.1285 - accuracy: 0.9770 - precision: 0.9885 - recall: 0.9652 - auc: 0.9968 - val_loss: 0.1320 - val_accuracy: 0.9770 - val_precision: 0.9885 - val_recall: 0.9653 - val_auc: 0.9968\n",
      "Epoch 198/200\n",
      "99854/99854 [==============================] - 2s 24us/step - loss: 0.1286 - accuracy: 0.9770 - precision: 0.9885 - recall: 0.9653 - auc: 0.9968 - val_loss: 0.1373 - val_accuracy: 0.9771 - val_precision: 0.9885 - val_recall: 0.9653 - val_auc: 0.9968\n",
      "Epoch 199/200\n",
      "99854/99854 [==============================] - 2s 24us/step - loss: 0.1284 - accuracy: 0.9771 - precision: 0.9885 - recall: 0.9653 - auc: 0.9968 - val_loss: 0.1342 - val_accuracy: 0.9771 - val_precision: 0.9885 - val_recall: 0.9653 - val_auc: 0.9968\n",
      "Epoch 200/200\n",
      "99854/99854 [==============================] - 2s 24us/step - loss: 0.1282 - accuracy: 0.9771 - precision: 0.9885 - recall: 0.9653 - auc: 0.9968 - val_loss: 0.1302 - val_accuracy: 0.9771 - val_precision: 0.9885 - val_recall: 0.9653 - val_auc: 0.9968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x26ea7d91f28>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=neural_network)\n",
    "estimator.fit(X_train,Y_train,verbose=1,callbacks=[early_stopping], epochs=200,validation_data=(X_val,Y_val), batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "4628/4628 [==============================] - 0s 107us/step - loss: 6.4053 - accuracy: 0.9771 - precision: 0.9885 - recall: 0.9653 - auc: 0.9968\n",
      "Epoch 1/1\n",
      "4628/4628 [==============================] - 0s 108us/step - loss: 6.4057 - accuracy: 0.9770 - precision: 0.9885 - recall: 0.9652 - auc: 0.9968\n",
      "Epoch 1/1\n",
      "4628/4628 [==============================] - 0s 107us/step - loss: 6.4526 - accuracy: 0.9770 - precision: 0.9885 - recall: 0.9652 - auc: 0.9968\n",
      "Cross-Validation set accuracy: 89.455488 %\n",
      "99854/99854 [==============================] - 3s 31us/step\n",
      "Train set accuracy           : 97.7031 %\n",
      "Test set accuracy            : 78.6688 %\n",
      "Test set precision           : 92.3700 %\n",
      "Test set recall              : 67.8333 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross-Validation set accuracy: {:.6f} %\".format((cross_val_score(estimator, X_val, Y_val, \n",
    "                                                                        cv=3,scoring='accuracy').mean())*100))\n",
    "test_predictions = estimator.predict(X_test)\n",
    "print(\"Train set accuracy           : {:.4f} %\".format(estimator.score(X_train,Y_train)*100))\n",
    "print(\"Test set accuracy            : {:.4f} %\".format(accuracy_score(Y_test, test_predictions)*100))\n",
    "print(\"Test set precision           : {:.4f} %\".format(precision_score(Y_test, test_predictions)*100))\n",
    "print(\"Test set recall              : {:.4f} %\".format(recall_score(Y_test, test_predictions)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "  metrics =  ['accuracy', 'precision', 'recall','auc']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplots(2,2)\n",
    "    plt.plot(history.epochs,  history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epochs, history.history['val_'+metric], color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'accuracy':\n",
    "      plt.ylim([0.8,1])\n",
    "    elif metric == 'precision':\n",
    "      plt.ylim([0.8,1])\n",
    "    elif metric == 'recall':\n",
    "      plt.ylim([0.8,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasClassifier' object has no attribute 'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-59f7d85a0aa5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-cb4df212ad2e>\u001b[0m in \u001b[0;36mplot_metrics\u001b[1;34m(history)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"--\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Val'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'epochs'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.81):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    plt.text(0.3,2.6,'True Negatives  : '+ str(cm[0][0]),size=14)\n",
    "    plt.text(0.3,2.8,'False Positives   : '+ str(cm[0][1]),size=14)\n",
    "    plt.text(0.3,3,'False Negatives : '+ str(cm[1][0]),size=14)\n",
    "    plt.text(0.3,3.2,'True Positives    : '+ str(cm[1][1]),size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cm(Y_test, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.93      0.79      9710\n",
      "           1       0.92      0.68      0.78     12600\n",
      "\n",
      "    accuracy                           0.79     22310\n",
      "   macro avg       0.81      0.80      0.79     22310\n",
      "weighted avg       0.82      0.79      0.79     22310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, test_predictions.round()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
