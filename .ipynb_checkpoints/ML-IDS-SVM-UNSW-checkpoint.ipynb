{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sharuka Thirimanne\\Desktop\\FYP-ML-IDS\n"
     ]
    }
   ],
   "source": [
    "cd C:\\\\Users\\\\Sharuka Thirimanne\\\\Desktop\\\\FYP-ML-IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_dataset():\n",
    "    df_train = pd.read_csv('Datasets/UNSW_NB15_training-set.csv')\n",
    "    df_test = pd.read_csv('Datasets/UNSW_NB15_testing-set.csv')\n",
    "    df = pd.concat([df_train,df_test], axis=0,sort=False)\n",
    "    df.drop(['id'], axis = 'columns' , inplace = True)\n",
    "    \n",
    "    #Below categories in the state feature are available in the test set but not in the training set\n",
    "    df.drop(df[df['state'] == 'CLO'].index, inplace = True)\n",
    "    df.drop(df[df['state'] == 'ACC'].index, inplace = True)\n",
    "    limit = df.shape[1]-1\n",
    "    \n",
    "    X = df.iloc[:,0:limit]\n",
    "    Y = df.iloc[:,limit]\n",
    "    \n",
    "    return  X, Y, df\n",
    "\n",
    "X, Y, df = load_train_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "categorical_cols = ['proto','service','state','attack_cat']\n",
    "array_hot_encoded = ohe.fit_transform(X[categorical_cols]).toarray()\n",
    "data_hot_encoded = pd.DataFrame(array_hot_encoded, index=X.index)\n",
    "X = X.drop(columns=categorical_cols)\n",
    "X = pd.concat([X,data_hot_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training X : (175468, 204)\n",
      "Test_X : (82195, 204)\n",
      "Training_Y : (175468,)\n",
      "Test_Y : (82195,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test , Y_train , Y_test = train_test_split(X, Y, test_size=0.319,shuffle=False)\n",
    "\n",
    "print('Training X :',X_train.shape)\n",
    "print('Test_X :',X_test.shape)\n",
    "print('Training_Y :',Y_train.shape)\n",
    "print('Test_Y :',Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (175341, 43)\n",
      "X_test shape: (82332, 43)\n",
      "Y_train shape: (175341,)\n",
      "Y_test shape: (82332,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:',X_train.shape)\n",
    "print('X_test shape:',X_test.shape)\n",
    "print('Y_train shape:',Y_train.shape)\n",
    "print('Y_test shape:',Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (175341, 43)\n",
      "X_test shape: (82332, 43)\n",
      "Y_train shape: (175341,)\n",
      "Y_test shape: (82332,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:',X_train.shape)\n",
    "print('X_test shape:',X_test.shape)\n",
    "print('Y_train shape:',Y_train.shape)\n",
    "print('Y_test shape:',Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "model = SVC(C= 50, gamma= 0.05,verbose=True).fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "model_poly = SVC(C= 15, kernel= 'poly',degree=4,gamma=0.5,verbose=True).fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "model_linear = SVC(C= 10, kernel= 'linear',verbose=True).fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RBF Kernel')\n",
    "test_predictions = model.predict(X_test)\n",
    "print(\"Train set accuracy           : {:.6f} %\".format(model.score(X_train,Y_train)*100))\n",
    "print(\"Cross-Validation set accuracy: {:.6f} %\".format((cross_val_score(model, X_train, Y_train, cv=3,scoring='accuracy').mean())*100))\n",
    "print(\"Test set accuracy            : {:.6f} %\".format(accuracy_score(Y_test, test_predictions)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Poly Kernel')\n",
    "test_predictions_poly = model_poly.predict(X_test)\n",
    "print(\"Train set accuracy           : {:.6f} %\".format(model_poly.score(X_train,Y_train)*100))\n",
    "print(\"Cross-Validation set accuracy: {:.6f} %\".format((cross_val_score(model_poly, X_train, Y_train, cv=3,scoring='accuracy').mean())*100))\n",
    "print(\"Test set accuracy            : {:.6f} %\".format(accuracy_score(Y_test, test_predictions_poly)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Linear Kernel')\n",
    "test_predictions_linear = model_linear.predict(X_test)\n",
    "print(\"Train set accuracy           : {:.6f} %\".format(model_linear.score(X_train,Y_train)*100))\n",
    "print(\"Cross-Validation set accuracy: {:.6f} %\".format((cross_val_score(model_linear, X_train, Y_train, cv=3,scoring='accuracy').mean())*100))\n",
    "print(\"Test set accuracy            : {:.6f} %\".format(accuracy_score(Y_test, test_predictions_linear)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [test_predictions,test_predictions_poly,test_predictions_linear]\n",
    "kernel_names = ['RBF','Poly','Linear']\n",
    "\n",
    "def plot_cm(labels, predictions,kernel_names, p=0.85):\n",
    "    fig, axs = plt.subplots(nrows = 1,ncols = 3, figsize=(20, 5))\n",
    "    for i in range(0,3): \n",
    "        pred = predictions[i]\n",
    "        k_names = kernel_names[i]\n",
    "        cm = confusion_matrix(labels, pred > p)\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\",ax=axs[i])\n",
    "        axs[i].set(xlabel='Predicted label',ylabel='Actual label',title=str('Confusion matrix @{:.2f}'.format(p))+' '+ str(k_names))\n",
    "        \n",
    "        axs[i].text(0.3,2.6,'True Negatives  : '+ str(cm[0][0]),size=18)\n",
    "        axs[i].text(0.3,2.8,'False Positives   : '+ str(cm[0][1]),size=18)\n",
    "        axs[i].text(0.3,3,'False Negatives : '+ str(cm[1][0]),size=18)\n",
    "        axs[i].text(0.3,3.2,'True Positives    : '+ str(cm[1][1]),size=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(test_Y, predictions,kernel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RBF Kernel Classification Report')\n",
    "print(classification_report(Y_test, test_predictions))\n",
    "print('\\n')\n",
    "print('Poly Kernel Classification Report')\n",
    "print(classification_report(Y_test, test_predictions_poly))\n",
    "print('\\n')\n",
    "print('Linear Kernel Classification Report')\n",
    "print(classification_report(Y_test, test_predictions_linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
