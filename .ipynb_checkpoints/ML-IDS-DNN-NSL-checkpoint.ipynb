{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN - NSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sharuka Thirimanne\\Desktop\\FYP-ML-IDS\n"
     ]
    }
   ],
   "source": [
    "cd C:\\\\Users\\\\Sharuka Thirimanne\\\\Desktop\\\\FYP-ML-IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sharuka thirimanne\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\sharuka thirimanne\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\sharuka thirimanne\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\sharuka thirimanne\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\sharuka thirimanne\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\sharuka thirimanne\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import Model, layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report,confusion_matrix,f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_train_dataset():\n",
    "    df_train = pd.read_csv('NSL_train-set.csv')\n",
    "    \n",
    "    limit = df_train.shape[1]-1\n",
    "    \n",
    "    X_train = df_train.iloc[:,0:limit]\n",
    "    Y_train = df_train.iloc[:,limit]\n",
    "    \n",
    "    return X_train, Y_train, df_train\n",
    "\n",
    "X_train, Y_train, df_train = load_train_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_dataset():\n",
    "    df_test = pd.read_csv('NSL_test-set.csv')\n",
    "\n",
    "    limit = df_test.shape[1]-1\n",
    "    \n",
    "    X_test = df_test.iloc[:,0:limit]\n",
    "    Y_test = df_test.iloc[:,limit]\n",
    "    \n",
    "    return X_test, Y_test, df_test\n",
    "\n",
    "X_test, Y_test, df_test = load_test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114324, 77)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [ \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='accuracy', \n",
    "    verbose=1,\n",
    "    patience=5,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114324, 77)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def neural_network(optimizer='sgd', init='glorot_uniform'):\n",
    "    #Neural Network Model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=77, activation='relu', kernel_initializer=init, bias_initializer='zeros'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics = METRICS)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 91459 samples, validate on 22865 samples\n",
      "Epoch 1/200\n",
      "91459/91459 [==============================] - 10s 107us/step - loss: 0.2690 - accuracy: 0.7934 - precision: 0.8857 - recall: 0.4923 - auc: 0.8970 - val_loss: 0.1119 - val_accuracy: 0.9089 - val_precision: 0.9805 - val_recall: 0.8081 - val_auc: 0.9746\n",
      "Epoch 2/200\n",
      "91459/91459 [==============================] - 9s 93us/step - loss: 0.0600 - accuracy: 0.9327 - precision: 0.9861 - recall: 0.8684 - auc: 0.9830 - val_loss: 0.1126 - val_accuracy: 0.9459 - val_precision: 0.9882 - val_recall: 0.8963 - val_auc: 0.9874\n",
      "Epoch 3/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0462 - accuracy: 0.9530 - precision: 0.9896 - recall: 0.9116 - auc: 0.9897 - val_loss: 0.0462 - val_accuracy: 0.9588 - val_precision: 0.9905 - val_recall: 0.9235 - val_auc: 0.9917\n",
      "Epoch 4/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0328 - accuracy: 0.9631 - precision: 0.9912 - recall: 0.9324 - auc: 0.9931 - val_loss: 0.0370 - val_accuracy: 0.9666 - val_precision: 0.9916 - val_recall: 0.9394 - val_auc: 0.9942\n",
      "Epoch 5/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0267 - accuracy: 0.9694 - precision: 0.9920 - recall: 0.9451 - auc: 0.9950 - val_loss: 0.0286 - val_accuracy: 0.9719 - val_precision: 0.9923 - val_recall: 0.9499 - val_auc: 0.9956\n",
      "Epoch 6/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0249 - accuracy: 0.9738 - precision: 0.9925 - recall: 0.9539 - auc: 0.9960 - val_loss: 0.0379 - val_accuracy: 0.9754 - val_precision: 0.9927 - val_recall: 0.9570 - val_auc: 0.9964\n",
      "Epoch 7/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0211 - accuracy: 0.9768 - precision: 0.9930 - recall: 0.9596 - auc: 0.9967 - val_loss: 0.0361 - val_accuracy: 0.9780 - val_precision: 0.9932 - val_recall: 0.9619 - val_auc: 0.9970.0213 - accuracy: 0.9766 - precision: 0.9930 - recall: 0.9594 - auc: 0.99 - ETA: 0s - loss: 0.0213 - accuracy: 0.9767 - precision: 0.9930 - recall: 0.9595\n",
      "Epoch 8/200\n",
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0195 - accuracy: 0.9790 - precision: 0.9934 - recall: 0.9639 - auc: 0.9972 - val_loss: 0.0236 - val_accuracy: 0.9800 - val_precision: 0.9935 - val_recall: 0.9658 - val_auc: 0.9974\n",
      "Epoch 9/200\n",
      "91459/91459 [==============================] - 9s 93us/step - loss: 0.0195 - accuracy: 0.9809 - precision: 0.9937 - recall: 0.9674 - auc: 0.9975 - val_loss: 0.0262 - val_accuracy: 0.9816 - val_precision: 0.9938 - val_recall: 0.9688 - val_auc: 0.9977\n",
      "Epoch 10/200\n",
      "91459/91459 [==============================] - 8s 92us/step - loss: 0.0184 - accuracy: 0.9823 - precision: 0.9939 - recall: 0.9701 - auc: 0.9978 - val_loss: 0.0376 - val_accuracy: 0.9829 - val_precision: 0.9940 - val_recall: 0.9712 - val_auc: 0.9979\n",
      "Epoch 11/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0172 - accuracy: 0.9834 - precision: 0.9941 - recall: 0.9723 - auc: 0.9980 - val_loss: 0.0423 - val_accuracy: 0.9839 - val_precision: 0.9942 - val_recall: 0.9731 - val_auc: 0.9981\n",
      "Epoch 12/200\n",
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0165 - accuracy: 0.9843 - precision: 0.9943 - recall: 0.9738 - auc: 0.9981 - val_loss: 0.0268 - val_accuracy: 0.9847 - val_precision: 0.9944 - val_recall: 0.9746 - val_auc: 0.9982\n",
      "Epoch 13/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0161 - accuracy: 0.9851 - precision: 0.9945 - recall: 0.9753 - auc: 0.9983 - val_loss: 0.0223 - val_accuracy: 0.9855 - val_precision: 0.9946 - val_recall: 0.9760 - val_auc: 0.9983\n",
      "Epoch 14/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0156 - accuracy: 0.9858 - precision: 0.9947 - recall: 0.9767 - auc: 0.9984 - val_loss: 0.0224 - val_accuracy: 0.9862 - val_precision: 0.9948 - val_recall: 0.9773 - val_auc: 0.9985\n",
      "Epoch 15/200\n",
      "91459/91459 [==============================] - 9s 98us/step - loss: 0.0148 - accuracy: 0.9865 - precision: 0.9949 - recall: 0.9779 - auc: 0.9985 - val_loss: 0.0157 - val_accuracy: 0.9868 - val_precision: 0.9949 - val_recall: 0.9784 - val_auc: 0.9985\n",
      "Epoch 16/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0150 - accuracy: 0.9871 - precision: 0.9950 - recall: 0.9790 - auc: 0.9986 - val_loss: 0.0195 - val_accuracy: 0.9874 - val_precision: 0.9951 - val_recall: 0.9794 - val_auc: 0.9986\n",
      "Epoch 17/200\n",
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0143 - accuracy: 0.9876 - precision: 0.9951 - recall: 0.9799 - auc: 0.9987 - val_loss: 0.0219 - val_accuracy: 0.9879 - val_precision: 0.9952 - val_recall: 0.9803 - val_auc: 0.9987\n",
      "Epoch 18/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0136 - accuracy: 0.9881 - precision: 0.9953 - recall: 0.9807 - auc: 0.9987 - val_loss: 0.0288 - val_accuracy: 0.9883 - val_precision: 0.9953 - val_recall: 0.9810 - val_auc: 0.9987\n",
      "Epoch 19/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0132 - accuracy: 0.9884 - precision: 0.9954 - recall: 0.9813 - auc: 0.9988 - val_loss: 0.0250 - val_accuracy: 0.9886 - val_precision: 0.9954 - val_recall: 0.9817 - val_auc: 0.9988\n",
      "Epoch 20/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0136 - accuracy: 0.9888 - precision: 0.9955 - recall: 0.9820 - auc: 0.9988 - val_loss: 0.0247 - val_accuracy: 0.9890 - val_precision: 0.9955 - val_recall: 0.9823 - val_auc: 0.9988\n",
      "Epoch 21/200\n",
      "91459/91459 [==============================] - 8s 92us/step - loss: 0.0129 - accuracy: 0.9891 - precision: 0.9956 - recall: 0.9826 - auc: 0.9989 - val_loss: 0.0246 - val_accuracy: 0.9893 - val_precision: 0.9956 - val_recall: 0.9828 - val_auc: 0.9989\n",
      "Epoch 22/200\n",
      "91459/91459 [==============================] - 10s 114us/step - loss: 0.0124 - accuracy: 0.9895 - precision: 0.9957 - recall: 0.9831 - auc: 0.9989 - val_loss: 0.0188 - val_accuracy: 0.9896 - val_precision: 0.9957 - val_recall: 0.9834 - val_auc: 0.9989\n",
      "Epoch 23/200\n",
      "91459/91459 [==============================] - 9s 103us/step - loss: 0.0118 - accuracy: 0.9897 - precision: 0.9957 - recall: 0.9836 - auc: 0.9989 - val_loss: 0.0376 - val_accuracy: 0.9899 - val_precision: 0.9958 - val_recall: 0.9838 - val_auc: 0.9989\n",
      "Epoch 24/200\n",
      "91459/91459 [==============================] - 10s 110us/step - loss: 0.0122 - accuracy: 0.9900 - precision: 0.9958 - recall: 0.9840 - auc: 0.9990 - val_loss: 0.0300 - val_accuracy: 0.9901 - val_precision: 0.9959 - val_recall: 0.9842 - val_auc: 0.9990\n",
      "Epoch 25/200\n",
      "91459/91459 [==============================] - 10s 107us/step - loss: 0.0118 - accuracy: 0.9902 - precision: 0.9959 - recall: 0.9844 - auc: 0.9990 - val_loss: 0.0282 - val_accuracy: 0.9903 - val_precision: 0.9959 - val_recall: 0.9846 - val_auc: 0.9990\n",
      "Epoch 26/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0115 - accuracy: 0.9905 - precision: 0.9960 - recall: 0.9848 - auc: 0.9990 - val_loss: 0.0132 - val_accuracy: 0.9906 - val_precision: 0.9960 - val_recall: 0.9850 - val_auc: 0.9990\n",
      "Epoch 27/200\n",
      "91459/91459 [==============================] - 9s 98us/step - loss: 0.0107 - accuracy: 0.9907 - precision: 0.9960 - recall: 0.9852 - auc: 0.9990 - val_loss: 0.0300 - val_accuracy: 0.9908 - val_precision: 0.9961 - val_recall: 0.9854 - val_auc: 0.9990\n",
      "Epoch 28/200\n",
      "91459/91459 [==============================] - 8s 91us/step - loss: 0.0110 - accuracy: 0.9909 - precision: 0.9961 - recall: 0.9856 - auc: 0.9991 - val_loss: 0.0215 - val_accuracy: 0.9910 - val_precision: 0.9961 - val_recall: 0.9857 - val_auc: 0.9991\n",
      "Epoch 29/200\n",
      "91459/91459 [==============================] - 9s 101us/step - loss: 0.0107 - accuracy: 0.9911 - precision: 0.9962 - recall: 0.9859 - auc: 0.9991 - val_loss: 0.0245 - val_accuracy: 0.9912 - val_precision: 0.9962 - val_recall: 0.9861 - val_auc: 0.9991\n",
      "Epoch 30/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0099 - accuracy: 0.9913 - precision: 0.9962 - recall: 0.9862 - auc: 0.9991 - val_loss: 0.0123 - val_accuracy: 0.9914 - val_precision: 0.9963 - val_recall: 0.9864 - val_auc: 0.9991\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91459/91459 [==============================] - 9s 93us/step - loss: 0.0102 - accuracy: 0.9915 - precision: 0.9963 - recall: 0.9865 - auc: 0.9991 - val_loss: 0.0249 - val_accuracy: 0.9915 - val_precision: 0.9963 - val_recall: 0.9867 - val_auc: 0.9991\n",
      "Epoch 32/200\n",
      "91459/91459 [==============================] - 9s 101us/step - loss: 0.0104 - accuracy: 0.9916 - precision: 0.9964 - recall: 0.9868 - auc: 0.9991 - val_loss: 0.0143 - val_accuracy: 0.9917 - val_precision: 0.9964 - val_recall: 0.9869 - val_auc: 0.9991\n",
      "Epoch 33/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0098 - accuracy: 0.9918 - precision: 0.9964 - recall: 0.9871 - auc: 0.9991 - val_loss: 0.0266 - val_accuracy: 0.9918 - val_precision: 0.9964 - val_recall: 0.9872 - val_auc: 0.9992\n",
      "Epoch 34/200\n",
      "91459/91459 [==============================] - 8s 91us/step - loss: 0.0097 - accuracy: 0.9919 - precision: 0.9965 - recall: 0.9873 - auc: 0.9992 - val_loss: 0.0191 - val_accuracy: 0.9920 - val_precision: 0.9965 - val_recall: 0.9874 - val_auc: 0.9992\n",
      "Epoch 35/200\n",
      "91459/91459 [==============================] - 8s 87us/step - loss: 0.0101 - accuracy: 0.9920 - precision: 0.9965 - recall: 0.9875 - auc: 0.9992 - val_loss: 0.0197 - val_accuracy: 0.9921 - val_precision: 0.9965 - val_recall: 0.9876 - val_auc: 0.9992\n",
      "Epoch 36/200\n",
      "91459/91459 [==============================] - 8s 90us/step - loss: 0.0104 - accuracy: 0.9922 - precision: 0.9965 - recall: 0.9877 - auc: 0.9992 - val_loss: 0.0253 - val_accuracy: 0.9922 - val_precision: 0.9966 - val_recall: 0.9878 - val_auc: 0.9992\n",
      "Epoch 37/200\n",
      "91459/91459 [==============================] - 8s 93us/step - loss: 0.0094 - accuracy: 0.9923 - precision: 0.9966 - recall: 0.9879 - auc: 0.9992 - val_loss: 0.0237 - val_accuracy: 0.9923 - val_precision: 0.9966 - val_recall: 0.9880 - val_auc: 0.9992\n",
      "Epoch 38/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0094 - accuracy: 0.9924 - precision: 0.9966 - recall: 0.9881 - auc: 0.9992 - val_loss: 0.0181 - val_accuracy: 0.9925 - val_precision: 0.9966 - val_recall: 0.9882 - val_auc: 0.9992\n",
      "Epoch 39/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0094 - accuracy: 0.9925 - precision: 0.9967 - recall: 0.9883 - auc: 0.9992 - val_loss: 0.0189 - val_accuracy: 0.9926 - val_precision: 0.9967 - val_recall: 0.9884 - val_auc: 0.9992\n",
      "Epoch 40/200\n",
      "91459/91459 [==============================] - 8s 92us/step - loss: 0.0088 - accuracy: 0.9926 - precision: 0.9967 - recall: 0.9885 - auc: 0.9992 - val_loss: 0.0244 - val_accuracy: 0.9927 - val_precision: 0.9967 - val_recall: 0.9886 - val_auc: 0.9993\n",
      "Epoch 41/200\n",
      "91459/91459 [==============================] - 8s 93us/step - loss: 0.0086 - accuracy: 0.9927 - precision: 0.9967 - recall: 0.9886 - auc: 0.9993 - val_loss: 0.0181 - val_accuracy: 0.9928 - val_precision: 0.9968 - val_recall: 0.9887 - val_auc: 0.9993\n",
      "Epoch 42/200\n",
      "91459/91459 [==============================] - 8s 91us/step - loss: 0.0086 - accuracy: 0.9928 - precision: 0.9968 - recall: 0.9888 - auc: 0.9993 - val_loss: 0.0273 - val_accuracy: 0.9929 - val_precision: 0.9968 - val_recall: 0.9889 - val_auc: 0.9993\n",
      "Epoch 43/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0087 - accuracy: 0.9929 - precision: 0.9968 - recall: 0.9890 - auc: 0.9993 - val_loss: 0.0194 - val_accuracy: 0.9930 - val_precision: 0.9968 - val_recall: 0.9890 - val_auc: 0.9993\n",
      "Epoch 44/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0087 - accuracy: 0.9930 - precision: 0.9968 - recall: 0.9891 - auc: 0.9993 - val_loss: 0.0159 - val_accuracy: 0.9931 - val_precision: 0.9969 - val_recall: 0.9892 - val_auc: 0.9993\n",
      "Epoch 45/200\n",
      "91459/91459 [==============================] - 9s 100us/step - loss: 0.0083 - accuracy: 0.9931 - precision: 0.9969 - recall: 0.9893 - auc: 0.9993 - val_loss: 0.0167 - val_accuracy: 0.9931 - val_precision: 0.9969 - val_recall: 0.9893 - val_auc: 0.9993\n",
      "Epoch 46/200\n",
      "91459/91459 [==============================] - 9s 100us/step - loss: 0.0085 - accuracy: 0.9932 - precision: 0.9969 - recall: 0.9894 - auc: 0.9993 - val_loss: 0.0244 - val_accuracy: 0.9932 - val_precision: 0.9969 - val_recall: 0.9895 - val_auc: 0.9993\n",
      "Epoch 47/200\n",
      "91459/91459 [==============================] - 9s 99us/step - loss: 0.0081 - accuracy: 0.9933 - precision: 0.9969 - recall: 0.9895 - auc: 0.9993 - val_loss: 0.0204 - val_accuracy: 0.9933 - val_precision: 0.9970 - val_recall: 0.9896 - val_auc: 0.9993\n",
      "Epoch 48/200\n",
      "91459/91459 [==============================] - 9s 103us/step - loss: 0.0077 - accuracy: 0.9934 - precision: 0.9970 - recall: 0.9897 - auc: 0.9993 - val_loss: 0.0241 - val_accuracy: 0.9934 - val_precision: 0.9970 - val_recall: 0.9897 - val_auc: 0.9993\n",
      "Epoch 49/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0080 - accuracy: 0.9934 - precision: 0.9970 - recall: 0.9898 - auc: 0.9993 - val_loss: 0.0152 - val_accuracy: 0.9935 - val_precision: 0.9970 - val_recall: 0.9899 - val_auc: 0.9993\n",
      "Epoch 50/200\n",
      "91459/91459 [==============================] - 9s 103us/step - loss: 0.0075 - accuracy: 0.9935 - precision: 0.9970 - recall: 0.9899 - auc: 0.9993 - val_loss: 0.0226 - val_accuracy: 0.9935 - val_precision: 0.9970 - val_recall: 0.9900 - val_auc: 0.9993\n",
      "Epoch 51/200\n",
      "91459/91459 [==============================] - 9s 99us/step - loss: 0.0075 - accuracy: 0.9936 - precision: 0.9971 - recall: 0.9900 - auc: 0.9993 - val_loss: 0.0182 - val_accuracy: 0.9936 - val_precision: 0.9971 - val_recall: 0.9901 - val_auc: 0.9994\n",
      "Epoch 52/200\n",
      "91459/91459 [==============================] - 9s 101us/step - loss: 0.0075 - accuracy: 0.9936 - precision: 0.9971 - recall: 0.9902 - auc: 0.9994 - val_loss: 0.0200 - val_accuracy: 0.9937 - val_precision: 0.9971 - val_recall: 0.9902 - val_auc: 0.9994\n",
      "Epoch 53/200\n",
      "91459/91459 [==============================] - 9s 101us/step - loss: 0.0073 - accuracy: 0.9937 - precision: 0.9971 - recall: 0.9903 - auc: 0.9994 - val_loss: 0.0273 - val_accuracy: 0.9937 - val_precision: 0.9971 - val_recall: 0.9903 - val_auc: 0.9994\n",
      "Epoch 54/200\n",
      "91459/91459 [==============================] - 9s 101us/step - loss: 0.0074 - accuracy: 0.9938 - precision: 0.9971 - recall: 0.9904 - auc: 0.9994 - val_loss: 0.0269 - val_accuracy: 0.9938 - val_precision: 0.9972 - val_recall: 0.9904 - val_auc: 0.9994\n",
      "Epoch 55/200\n",
      "91459/91459 [==============================] - 9s 100us/step - loss: 0.0075 - accuracy: 0.9938 - precision: 0.9972 - recall: 0.9905 - auc: 0.9994 - val_loss: 0.0255 - val_accuracy: 0.9939 - val_precision: 0.9972 - val_recall: 0.9905 - val_auc: 0.9994\n",
      "Epoch 56/200\n",
      "91459/91459 [==============================] - 9s 99us/step - loss: 0.0073 - accuracy: 0.9939 - precision: 0.9972 - recall: 0.9905 - auc: 0.9994 - val_loss: 0.0272 - val_accuracy: 0.9939 - val_precision: 0.9972 - val_recall: 0.9906 - val_auc: 0.9994\n",
      "Epoch 57/200\n",
      "91459/91459 [==============================] - 9s 99us/step - loss: 0.0076 - accuracy: 0.9939 - precision: 0.9972 - recall: 0.9906 - auc: 0.9994 - val_loss: 0.0253 - val_accuracy: 0.9940 - val_precision: 0.9972 - val_recall: 0.9907 - val_auc: 0.9994\n",
      "Epoch 58/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0075 - accuracy: 0.9940 - precision: 0.9972 - recall: 0.9907 - auc: 0.9994 - val_loss: 0.0157 - val_accuracy: 0.9940 - val_precision: 0.9972 - val_recall: 0.9908 - val_auc: 0.9994\n",
      "Epoch 59/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0073 - accuracy: 0.9941 - precision: 0.9973 - recall: 0.9908 - auc: 0.9994 - val_loss: 0.0175 - val_accuracy: 0.9941 - val_precision: 0.9973 - val_recall: 0.9909 - val_auc: 0.9994\n",
      "Epoch 60/200\n",
      "91459/91459 [==============================] - 9s 99us/step - loss: 0.0070 - accuracy: 0.9941 - precision: 0.9973 - recall: 0.9909 - auc: 0.9994 - val_loss: 0.0158 - val_accuracy: 0.9941 - val_precision: 0.9973 - val_recall: 0.9910 - val_auc: 0.9994\n",
      "Epoch 61/200\n",
      "91459/91459 [==============================] - 9s 101us/step - loss: 0.0072 - accuracy: 0.9942 - precision: 0.9973 - recall: 0.9910 - auc: 0.9994 - val_loss: 0.0202 - val_accuracy: 0.9942 - val_precision: 0.9973 - val_recall: 0.9910 - val_auc: 0.9994\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91459/91459 [==============================] - 8s 91us/step - loss: 0.0069 - accuracy: 0.9942 - precision: 0.9973 - recall: 0.9911 - auc: 0.9994 - val_loss: 0.0300 - val_accuracy: 0.9942 - val_precision: 0.9973 - val_recall: 0.9911 - val_auc: 0.9994\n",
      "Epoch 63/200\n",
      "91459/91459 [==============================] - 8s 92us/step - loss: 0.0068 - accuracy: 0.9943 - precision: 0.9973 - recall: 0.9911 - auc: 0.9994 - val_loss: 0.0191 - val_accuracy: 0.9943 - val_precision: 0.9973 - val_recall: 0.9912 - val_auc: 0.9994\n",
      "Epoch 64/200\n",
      "91459/91459 [==============================] - 9s 102us/step - loss: 0.0068 - accuracy: 0.9943 - precision: 0.9974 - recall: 0.9912 - auc: 0.9994 - val_loss: 0.0175 - val_accuracy: 0.9943 - val_precision: 0.9974 - val_recall: 0.9913 - val_auc: 0.9994\n",
      "Epoch 65/200\n",
      "91459/91459 [==============================] - 9s 99us/step - loss: 0.0066 - accuracy: 0.9944 - precision: 0.9974 - recall: 0.9913 - auc: 0.9994 - val_loss: 0.0190 - val_accuracy: 0.9944 - val_precision: 0.9974 - val_recall: 0.9913 - val_auc: 0.9994\n",
      "Epoch 66/200\n",
      "91459/91459 [==============================] - 8s 92us/step - loss: 0.0064 - accuracy: 0.9944 - precision: 0.9974 - recall: 0.9914 - auc: 0.9994 - val_loss: 0.0218 - val_accuracy: 0.9944 - val_precision: 0.9974 - val_recall: 0.9914 - val_auc: 0.9994\n",
      "Epoch 67/200\n",
      "91459/91459 [==============================] - 8s 87us/step - loss: 0.0070 - accuracy: 0.9944 - precision: 0.9974 - recall: 0.9914 - auc: 0.9995 - val_loss: 0.0208 - val_accuracy: 0.9945 - val_precision: 0.9974 - val_recall: 0.9915 - val_auc: 0.9995\n",
      "Epoch 68/200\n",
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0068 - accuracy: 0.9945 - precision: 0.9974 - recall: 0.9915 - auc: 0.9995 - val_loss: 0.0224 - val_accuracy: 0.9945 - val_precision: 0.9974 - val_recall: 0.9915 - val_auc: 0.9995\n",
      "Epoch 69/200\n",
      "91459/91459 [==============================] - 8s 91us/step - loss: 0.0066 - accuracy: 0.9945 - precision: 0.9974 - recall: 0.9916 - auc: 0.9995 - val_loss: 0.0141 - val_accuracy: 0.9945 - val_precision: 0.9975 - val_recall: 0.9916 - val_auc: 0.9995\n",
      "Epoch 70/200\n",
      "91459/91459 [==============================] - 8s 92us/step - loss: 0.0068 - accuracy: 0.9946 - precision: 0.9975 - recall: 0.9916 - auc: 0.9995 - val_loss: 0.0213 - val_accuracy: 0.9946 - val_precision: 0.9975 - val_recall: 0.9917 - val_auc: 0.9995\n",
      "Epoch 71/200\n",
      "91459/91459 [==============================] - 8s 92us/step - loss: 0.0067 - accuracy: 0.9946 - precision: 0.9975 - recall: 0.9917 - auc: 0.9995 - val_loss: 0.0176 - val_accuracy: 0.9946 - val_precision: 0.9975 - val_recall: 0.9917 - val_auc: 0.9995\n",
      "Epoch 72/200\n",
      "91459/91459 [==============================] - 9s 93us/step - loss: 0.0064 - accuracy: 0.9947 - precision: 0.9975 - recall: 0.9918 - auc: 0.9995 - val_loss: 0.0164 - val_accuracy: 0.9947 - val_precision: 0.9975 - val_recall: 0.9918 - val_auc: 0.9995\n",
      "Epoch 73/200\n",
      "91459/91459 [==============================] - 9s 104us/step - loss: 0.0064 - accuracy: 0.9947 - precision: 0.9975 - recall: 0.9919 - auc: 0.9995 - val_loss: 0.0215 - val_accuracy: 0.9947 - val_precision: 0.9975 - val_recall: 0.9919 - val_auc: 0.9995\n",
      "Epoch 74/200\n",
      "91459/91459 [==============================] - 9s 93us/step - loss: 0.0066 - accuracy: 0.9947 - precision: 0.9975 - recall: 0.9919 - auc: 0.9995 - val_loss: 0.0213 - val_accuracy: 0.9947 - val_precision: 0.9975 - val_recall: 0.9919 - val_auc: 0.9995\n",
      "Epoch 75/200\n",
      "91459/91459 [==============================] - 8s 92us/step - loss: 0.0064 - accuracy: 0.9947 - precision: 0.9975 - recall: 0.9919 - auc: 0.9995 - val_loss: 0.0288 - val_accuracy: 0.9948 - val_precision: 0.9975 - val_recall: 0.9920 - val_auc: 0.9995\n",
      "Epoch 76/200\n",
      "91459/91459 [==============================] - 8s 89us/step - loss: 0.0063 - accuracy: 0.9948 - precision: 0.9976 - recall: 0.9920 - auc: 0.9995 - val_loss: 0.0338 - val_accuracy: 0.9948 - val_precision: 0.9976 - val_recall: 0.9920 - val_auc: 0.9995\n",
      "Epoch 77/200\n",
      "91459/91459 [==============================] - 8s 90us/step - loss: 0.0065 - accuracy: 0.9948 - precision: 0.9976 - recall: 0.9920 - auc: 0.9995 - val_loss: 0.0229 - val_accuracy: 0.9948 - val_precision: 0.9976 - val_recall: 0.9921 - val_auc: 0.9995\n",
      "Epoch 78/200\n",
      "91459/91459 [==============================] - 9s 100us/step - loss: 0.0069 - accuracy: 0.9948 - precision: 0.9976 - recall: 0.9921 - auc: 0.9995 - val_loss: 0.0191 - val_accuracy: 0.9949 - val_precision: 0.9976 - val_recall: 0.9921 - val_auc: 0.9995\n",
      "Epoch 79/200\n",
      "91459/91459 [==============================] - 9s 93us/step - loss: 0.0067 - accuracy: 0.9949 - precision: 0.9976 - recall: 0.9921 - auc: 0.9995 - val_loss: 0.0205 - val_accuracy: 0.9949 - val_precision: 0.9976 - val_recall: 0.9922 - val_auc: 0.9995\n",
      "Epoch 80/200\n",
      "91459/91459 [==============================] - 9s 100us/step - loss: 0.0062 - accuracy: 0.9949 - precision: 0.9976 - recall: 0.9922 - auc: 0.9995 - val_loss: 0.0187 - val_accuracy: 0.9949 - val_precision: 0.9976 - val_recall: 0.9922 - val_auc: 0.9995\n",
      "Epoch 81/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0060 - accuracy: 0.9949 - precision: 0.9976 - recall: 0.9922 - auc: 0.9995 - val_loss: 0.0213 - val_accuracy: 0.9949 - val_precision: 0.9976 - val_recall: 0.9923 - val_auc: 0.9995\n",
      "Epoch 82/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0061 - accuracy: 0.9950 - precision: 0.9976 - recall: 0.9923 - auc: 0.9995 - val_loss: 0.0277 - val_accuracy: 0.9950 - val_precision: 0.9976 - val_recall: 0.9923 - val_auc: 0.9995\n",
      "Epoch 83/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0061 - accuracy: 0.9950 - precision: 0.9976 - recall: 0.9923 - auc: 0.9995 - val_loss: 0.0190 - val_accuracy: 0.9950 - val_precision: 0.9976 - val_recall: 0.9923 - val_auc: 0.9995\n",
      "Epoch 84/200\n",
      "91459/91459 [==============================] - 9s 100us/step - loss: 0.0061 - accuracy: 0.9950 - precision: 0.9976 - recall: 0.9924 - auc: 0.9995 - val_loss: 0.0209 - val_accuracy: 0.9950 - val_precision: 0.9977 - val_recall: 0.9924 - val_auc: 0.9995\n",
      "Epoch 85/200\n",
      "91459/91459 [==============================] - 10s 108us/step - loss: 0.0063 - accuracy: 0.9951 - precision: 0.9977 - recall: 0.9924 - auc: 0.9995 - val_loss: 0.0238 - val_accuracy: 0.9951 - val_precision: 0.9977 - val_recall: 0.9924 - val_auc: 0.9995\n",
      "Epoch 86/200\n",
      "91459/91459 [==============================] - 9s 102us/step - loss: 0.0061 - accuracy: 0.9951 - precision: 0.9977 - recall: 0.9925 - auc: 0.9995 - val_loss: 0.0177 - val_accuracy: 0.9951 - val_precision: 0.9977 - val_recall: 0.9925 - val_auc: 0.9995\n",
      "Epoch 87/200\n",
      "91459/91459 [==============================] - 8s 93us/step - loss: 0.0060 - accuracy: 0.9951 - precision: 0.9977 - recall: 0.9925 - auc: 0.9995 - val_loss: 0.0228 - val_accuracy: 0.9951 - val_precision: 0.9977 - val_recall: 0.9925 - val_auc: 0.9995: 0.0059 - accuracy: 0.9951 - precision: 0.9977 - recall: 0.992\n",
      "Epoch 88/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0059 - accuracy: 0.9951 - precision: 0.9977 - recall: 0.9925 - auc: 0.9995 - val_loss: 0.0163 - val_accuracy: 0.9951 - val_precision: 0.9977 - val_recall: 0.9926 - val_auc: 0.9995\n",
      "Epoch 89/200\n",
      "91459/91459 [==============================] - 9s 99us/step - loss: 0.0060 - accuracy: 0.9952 - precision: 0.9977 - recall: 0.9926 - auc: 0.9995 - val_loss: 0.0232 - val_accuracy: 0.9952 - val_precision: 0.9977 - val_recall: 0.9926 - val_auc: 0.9995\n",
      "Epoch 90/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0058 - accuracy: 0.9952 - precision: 0.9977 - recall: 0.9926 - auc: 0.9995 - val_loss: 0.0302 - val_accuracy: 0.9952 - val_precision: 0.9977 - val_recall: 0.9926 - val_auc: 0.9995\n",
      "Epoch 91/200\n",
      "91459/91459 [==============================] - 8s 93us/step - loss: 0.0058 - accuracy: 0.9952 - precision: 0.9977 - recall: 0.9927 - auc: 0.9995 - val_loss: 0.0204 - val_accuracy: 0.9952 - val_precision: 0.9977 - val_recall: 0.9927 - val_auc: 0.9995\n",
      "Epoch 92/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0059 - accuracy: 0.9952 - precision: 0.9977 - recall: 0.9927 - auc: 0.9995 - val_loss: 0.0451 - val_accuracy: 0.9952 - val_precision: 0.9977 - val_recall: 0.9927 - val_auc: 0.9995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200\n",
      "91459/91459 [==============================] - 9s 101us/step - loss: 0.0060 - accuracy: 0.9952 - precision: 0.9977 - recall: 0.9927 - auc: 0.9995 - val_loss: 0.0196 - val_accuracy: 0.9952 - val_precision: 0.9978 - val_recall: 0.9927 - val_auc: 0.9995\n",
      "Epoch 94/200\n",
      "91459/91459 [==============================] - 8s 92us/step - loss: 0.0059 - accuracy: 0.9953 - precision: 0.9977 - recall: 0.9927 - auc: 0.9995 - val_loss: 0.0298 - val_accuracy: 0.9953 - val_precision: 0.9978 - val_recall: 0.9928 - val_auc: 0.9995\n",
      "Epoch 95/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0060 - accuracy: 0.9953 - precision: 0.9978 - recall: 0.9928 - auc: 0.9995 - val_loss: 0.0149 - val_accuracy: 0.9953 - val_precision: 0.9978 - val_recall: 0.9928 - val_auc: 0.9995\n",
      "Epoch 96/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0060 - accuracy: 0.9953 - precision: 0.9978 - recall: 0.9928 - auc: 0.9995 - val_loss: 0.0188 - val_accuracy: 0.9953 - val_precision: 0.9978 - val_recall: 0.9928 - val_auc: 0.9995\n",
      "Epoch 97/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0058 - accuracy: 0.9953 - precision: 0.9978 - recall: 0.9929 - auc: 0.9996 - val_loss: 0.0187 - val_accuracy: 0.9953 - val_precision: 0.9978 - val_recall: 0.9929 - val_auc: 0.9995\n",
      "Epoch 98/200\n",
      "91459/91459 [==============================] - 9s 102us/step - loss: 0.0059 - accuracy: 0.9954 - precision: 0.9978 - recall: 0.9929 - auc: 0.9996 - val_loss: 0.0249 - val_accuracy: 0.9954 - val_precision: 0.9978 - val_recall: 0.9929 - val_auc: 0.9995\n",
      "Epoch 99/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0060 - accuracy: 0.9954 - precision: 0.9978 - recall: 0.9929 - auc: 0.9996 - val_loss: 0.0204 - val_accuracy: 0.9954 - val_precision: 0.9978 - val_recall: 0.9929 - val_auc: 0.9995\n",
      "Epoch 100/200\n",
      "91459/91459 [==============================] - 9s 99us/step - loss: 0.0060 - accuracy: 0.9954 - precision: 0.9978 - recall: 0.9929 - auc: 0.9996 - val_loss: 0.0242 - val_accuracy: 0.9954 - val_precision: 0.9978 - val_recall: 0.9930 - val_auc: 0.9996\n",
      "Epoch 101/200\n",
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0057 - accuracy: 0.9954 - precision: 0.9978 - recall: 0.9930 - auc: 0.9996 - val_loss: 0.0171 - val_accuracy: 0.9954 - val_precision: 0.9978 - val_recall: 0.9930 - val_auc: 0.9996\n",
      "Epoch 102/200\n",
      "91459/91459 [==============================] - 8s 90us/step - loss: 0.0057 - accuracy: 0.9954 - precision: 0.9978 - recall: 0.9930 - auc: 0.9996 - val_loss: 0.0227 - val_accuracy: 0.9954 - val_precision: 0.9978 - val_recall: 0.9930 - val_auc: 0.9996\n",
      "Epoch 103/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0056 - accuracy: 0.9955 - precision: 0.9978 - recall: 0.9930 - auc: 0.9996 - val_loss: 0.0312 - val_accuracy: 0.9955 - val_precision: 0.9978 - val_recall: 0.9930 - val_auc: 0.9996\n",
      "Epoch 104/200\n",
      "91459/91459 [==============================] - 8s 93us/step - loss: 0.0056 - accuracy: 0.9955 - precision: 0.9978 - recall: 0.9931 - auc: 0.9996 - val_loss: 0.0263 - val_accuracy: 0.9955 - val_precision: 0.9978 - val_recall: 0.9931 - val_auc: 0.9996\n",
      "Epoch 105/200\n",
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0056 - accuracy: 0.9955 - precision: 0.9979 - recall: 0.9931 - auc: 0.9996 - val_loss: 0.0199 - val_accuracy: 0.9955 - val_precision: 0.9979 - val_recall: 0.9931 - val_auc: 0.9996\n",
      "Epoch 106/200\n",
      "91459/91459 [==============================] - 8s 91us/step - loss: 0.0058 - accuracy: 0.9955 - precision: 0.9979 - recall: 0.9931 - auc: 0.9996 - val_loss: 0.0196 - val_accuracy: 0.9955 - val_precision: 0.9979 - val_recall: 0.9931 - val_auc: 0.9996\n",
      "Epoch 107/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0058 - accuracy: 0.9955 - precision: 0.9979 - recall: 0.9931 - auc: 0.9996 - val_loss: 0.0282 - val_accuracy: 0.9955 - val_precision: 0.9979 - val_recall: 0.9932 - val_auc: 0.9996\n",
      "Epoch 108/200\n",
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0057 - accuracy: 0.9955 - precision: 0.9979 - recall: 0.9932 - auc: 0.9996 - val_loss: 0.0183 - val_accuracy: 0.9955 - val_precision: 0.9979 - val_recall: 0.9932 - val_auc: 0.9996\n",
      "Epoch 109/200\n",
      "91459/91459 [==============================] - 8s 92us/step - loss: 0.0056 - accuracy: 0.9955 - precision: 0.9979 - recall: 0.9932 - auc: 0.9996 - val_loss: 0.0235 - val_accuracy: 0.9956 - val_precision: 0.9979 - val_recall: 0.9932 - val_auc: 0.9996\n",
      "Epoch 110/200\n",
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0056 - accuracy: 0.9956 - precision: 0.9979 - recall: 0.9932 - auc: 0.9996 - val_loss: 0.0168 - val_accuracy: 0.9956 - val_precision: 0.9979 - val_recall: 0.9932 - val_auc: 0.9996\n",
      "Epoch 111/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0055 - accuracy: 0.9956 - precision: 0.9979 - recall: 0.9933 - auc: 0.9996 - val_loss: 0.0260 - val_accuracy: 0.9956 - val_precision: 0.9979 - val_recall: 0.9933 - val_auc: 0.9996\n",
      "Epoch 112/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0054 - accuracy: 0.9956 - precision: 0.9979 - recall: 0.9933 - auc: 0.9996 - val_loss: 0.0229 - val_accuracy: 0.9956 - val_precision: 0.9979 - val_recall: 0.9933 - val_auc: 0.9996\n",
      "Epoch 113/200\n",
      "91459/91459 [==============================] - 8s 91us/step - loss: 0.0054 - accuracy: 0.9956 - precision: 0.9979 - recall: 0.9933 - auc: 0.9996 - val_loss: 0.0206 - val_accuracy: 0.9956 - val_precision: 0.9979 - val_recall: 0.9933 - val_auc: 0.9996\n",
      "Epoch 114/200\n",
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0055 - accuracy: 0.9956 - precision: 0.9979 - recall: 0.9933 - auc: 0.9996 - val_loss: 0.0200 - val_accuracy: 0.9956 - val_precision: 0.9979 - val_recall: 0.9933 - val_auc: 0.9996\n",
      "Epoch 115/200\n",
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0054 - accuracy: 0.9957 - precision: 0.9979 - recall: 0.9933 - auc: 0.9996 - val_loss: 0.0159 - val_accuracy: 0.9957 - val_precision: 0.9979 - val_recall: 0.9934 - val_auc: 0.9996\n",
      "Epoch 116/200\n",
      "91459/91459 [==============================] - 8s 92us/step - loss: 0.0054 - accuracy: 0.9957 - precision: 0.9979 - recall: 0.9934 - auc: 0.9996 - val_loss: 0.0251 - val_accuracy: 0.9957 - val_precision: 0.9979 - val_recall: 0.9934 - val_auc: 0.9996\n",
      "Epoch 117/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0053 - accuracy: 0.9957 - precision: 0.9979 - recall: 0.9934 - auc: 0.9996 - val_loss: 0.0127 - val_accuracy: 0.9957 - val_precision: 0.9979 - val_recall: 0.9934 - val_auc: 0.9996\n",
      "Epoch 118/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0054 - accuracy: 0.9957 - precision: 0.9979 - recall: 0.9934 - auc: 0.9996 - val_loss: 0.0215 - val_accuracy: 0.9957 - val_precision: 0.9980 - val_recall: 0.9934 - val_auc: 0.9996\n",
      "Epoch 119/200\n",
      "91459/91459 [==============================] - 9s 99us/step - loss: 0.0053 - accuracy: 0.9957 - precision: 0.9979 - recall: 0.9935 - auc: 0.9996 - val_loss: 0.0149 - val_accuracy: 0.9957 - val_precision: 0.9980 - val_recall: 0.9935 - val_auc: 0.9996\n",
      "Epoch 120/200\n",
      "91459/91459 [==============================] - 8s 93us/step - loss: 0.0054 - accuracy: 0.9957 - precision: 0.9980 - recall: 0.9935 - auc: 0.9996 - val_loss: 0.0158 - val_accuracy: 0.9957 - val_precision: 0.9980 - val_recall: 0.9935 - val_auc: 0.9996\n",
      "Epoch 121/200\n",
      "91459/91459 [==============================] - 9s 100us/step - loss: 0.0052 - accuracy: 0.9957 - precision: 0.9980 - recall: 0.9935 - auc: 0.9996 - val_loss: 0.0184 - val_accuracy: 0.9958 - val_precision: 0.9980 - val_recall: 0.9935 - val_auc: 0.9996\n",
      "Epoch 122/200\n",
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0054 - accuracy: 0.9958 - precision: 0.9980 - recall: 0.9935 - auc: 0.9996 - val_loss: 0.0124 - val_accuracy: 0.9958 - val_precision: 0.9980 - val_recall: 0.9936 - val_auc: 0.9996\n",
      "Epoch 123/200\n",
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0053 - accuracy: 0.9958 - precision: 0.9980 - recall: 0.9936 - auc: 0.9996 - val_loss: 0.0265 - val_accuracy: 0.9958 - val_precision: 0.9980 - val_recall: 0.9936 - val_auc: 0.9996\n",
      "Epoch 124/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0052 - accuracy: 0.9958 - precision: 0.9980 - recall: 0.9936 - auc: 0.9996 - val_loss: 0.0220 - val_accuracy: 0.9958 - val_precision: 0.9980 - val_recall: 0.9936 - val_auc: 0.9996\n",
      "Epoch 125/200\n",
      "91459/91459 [==============================] - 8s 90us/step - loss: 0.0052 - accuracy: 0.9958 - precision: 0.9980 - recall: 0.9936 - auc: 0.9996 - val_loss: 0.0111 - val_accuracy: 0.9958 - val_precision: 0.9980 - val_recall: 0.9936 - val_auc: 0.9996\n",
      "Epoch 126/200\n",
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0052 - accuracy: 0.9958 - precision: 0.9980 - recall: 0.9936 - auc: 0.9996 - val_loss: 0.0287 - val_accuracy: 0.9958 - val_precision: 0.9980 - val_recall: 0.9936 - val_auc: 0.9996\n",
      "Epoch 127/200\n",
      "91459/91459 [==============================] - 8s 92us/step - loss: 0.0051 - accuracy: 0.9958 - precision: 0.9980 - recall: 0.9937 - auc: 0.9996 - val_loss: 0.0159 - val_accuracy: 0.9958 - val_precision: 0.9980 - val_recall: 0.9937 - val_auc: 0.9996\n",
      "Epoch 128/200\n",
      "91459/91459 [==============================] - 10s 105us/step - loss: 0.0051 - accuracy: 0.9958 - precision: 0.9980 - recall: 0.9937 - auc: 0.9996 - val_loss: 0.0254 - val_accuracy: 0.9959 - val_precision: 0.9980 - val_recall: 0.9937 - val_auc: 0.9996\n",
      "Epoch 129/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0051 - accuracy: 0.9959 - precision: 0.9980 - recall: 0.9937 - auc: 0.9996 - val_loss: 0.0181 - val_accuracy: 0.9959 - val_precision: 0.9980 - val_recall: 0.9937 - val_auc: 0.9996\n",
      "Epoch 130/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0052 - accuracy: 0.9959 - precision: 0.9980 - recall: 0.9937 - auc: 0.9996 - val_loss: 0.0248 - val_accuracy: 0.9959 - val_precision: 0.9980 - val_recall: 0.9937 - val_auc: 0.9996\n",
      "Epoch 131/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0052 - accuracy: 0.9959 - precision: 0.9980 - recall: 0.9937 - auc: 0.9996 - val_loss: 0.0194 - val_accuracy: 0.9959 - val_precision: 0.9980 - val_recall: 0.9937 - val_auc: 0.9996\n",
      "Epoch 132/200\n",
      "91459/91459 [==============================] - 9s 98us/step - loss: 0.0052 - accuracy: 0.9959 - precision: 0.9980 - recall: 0.9938 - auc: 0.9996 - val_loss: 0.0235 - val_accuracy: 0.9959 - val_precision: 0.9980 - val_recall: 0.9938 - val_auc: 0.9996\n",
      "Epoch 133/200\n",
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0052 - accuracy: 0.9959 - precision: 0.9980 - recall: 0.9938 - auc: 0.9996 - val_loss: 0.0140 - val_accuracy: 0.9959 - val_precision: 0.9980 - val_recall: 0.9938 - val_auc: 0.9996\n",
      "Epoch 134/200\n",
      "91459/91459 [==============================] - 8s 92us/step - loss: 0.0050 - accuracy: 0.9959 - precision: 0.9980 - recall: 0.9938 - auc: 0.9996 - val_loss: 0.0143 - val_accuracy: 0.9959 - val_precision: 0.9980 - val_recall: 0.9938 - val_auc: 0.9996\n",
      "Epoch 135/200\n",
      "91459/91459 [==============================] - 9s 100us/step - loss: 0.0052 - accuracy: 0.9959 - precision: 0.9980 - recall: 0.9938 - auc: 0.9996 - val_loss: 0.0276 - val_accuracy: 0.9959 - val_precision: 0.9980 - val_recall: 0.9938 - val_auc: 0.9996\n",
      "Epoch 136/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0052 - accuracy: 0.9960 - precision: 0.9980 - recall: 0.9938 - auc: 0.9996 - val_loss: 0.0226 - val_accuracy: 0.9960 - val_precision: 0.9981 - val_recall: 0.9938 - val_auc: 0.9996\n",
      "Epoch 137/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0052 - accuracy: 0.9960 - precision: 0.9981 - recall: 0.9938 - auc: 0.9996 - val_loss: 0.0189 - val_accuracy: 0.9960 - val_precision: 0.9981 - val_recall: 0.9939 - val_auc: 0.9996\n",
      "Epoch 138/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0051 - accuracy: 0.9960 - precision: 0.9981 - recall: 0.9939 - auc: 0.9996 - val_loss: 0.0207 - val_accuracy: 0.9960 - val_precision: 0.9981 - val_recall: 0.9939 - val_auc: 0.9996\n",
      "Epoch 139/200\n",
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0051 - accuracy: 0.9960 - precision: 0.9981 - recall: 0.9939 - auc: 0.9996 - val_loss: 0.0179 - val_accuracy: 0.9960 - val_precision: 0.9981 - val_recall: 0.9939 - val_auc: 0.9996\n",
      "Epoch 140/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0050 - accuracy: 0.9960 - precision: 0.9981 - recall: 0.9939 - auc: 0.9996 - val_loss: 0.0210 - val_accuracy: 0.9960 - val_precision: 0.9981 - val_recall: 0.9939 - val_auc: 0.9996\n",
      "Epoch 141/200\n",
      "91459/91459 [==============================] - 8s 92us/step - loss: 0.0051 - accuracy: 0.9960 - precision: 0.9981 - recall: 0.9939 - auc: 0.9996 - val_loss: 0.0192 - val_accuracy: 0.9960 - val_precision: 0.9981 - val_recall: 0.9939 - val_auc: 0.9996\n",
      "Epoch 142/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0048 - accuracy: 0.9960 - precision: 0.9981 - recall: 0.9939 - auc: 0.9996 - val_loss: 0.0168 - val_accuracy: 0.9960 - val_precision: 0.9981 - val_recall: 0.9940 - val_auc: 0.9996\n",
      "Epoch 143/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0053 - accuracy: 0.9960 - precision: 0.9981 - recall: 0.9940 - auc: 0.9996 - val_loss: 0.0246 - val_accuracy: 0.9960 - val_precision: 0.9981 - val_recall: 0.9940 - val_auc: 0.9996\n",
      "Epoch 144/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0050 - accuracy: 0.9960 - precision: 0.9981 - recall: 0.9940 - auc: 0.9996 - val_loss: 0.0227 - val_accuracy: 0.9960 - val_precision: 0.9981 - val_recall: 0.9940 - val_auc: 0.9996\n",
      "Epoch 145/200\n",
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0052 - accuracy: 0.9960 - precision: 0.9981 - recall: 0.9940 - auc: 0.9996 - val_loss: 0.0178 - val_accuracy: 0.9961 - val_precision: 0.9981 - val_recall: 0.9940 - val_auc: 0.9996\n",
      "Epoch 146/200\n",
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0053 - accuracy: 0.9961 - precision: 0.9981 - recall: 0.9940 - auc: 0.9996 - val_loss: 0.0211 - val_accuracy: 0.9961 - val_precision: 0.9981 - val_recall: 0.9940 - val_auc: 0.9996\n",
      "Epoch 147/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0051 - accuracy: 0.9961 - precision: 0.9981 - recall: 0.9940 - auc: 0.9996 - val_loss: 0.0180 - val_accuracy: 0.9961 - val_precision: 0.9981 - val_recall: 0.9940 - val_auc: 0.9996\n",
      "Epoch 148/200\n",
      "91459/91459 [==============================] - 9s 93us/step - loss: 0.0049 - accuracy: 0.9961 - precision: 0.9981 - recall: 0.9941 - auc: 0.9996 - val_loss: 0.0175 - val_accuracy: 0.9961 - val_precision: 0.9981 - val_recall: 0.9941 - val_auc: 0.9996\n",
      "Epoch 149/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0049 - accuracy: 0.9961 - precision: 0.9981 - recall: 0.9941 - auc: 0.9996 - val_loss: 0.0214 - val_accuracy: 0.9961 - val_precision: 0.9981 - val_recall: 0.9941 - val_auc: 0.9996\n",
      "Epoch 150/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0048 - accuracy: 0.9961 - precision: 0.9981 - recall: 0.9941 - auc: 0.9996 - val_loss: 0.0167 - val_accuracy: 0.9961 - val_precision: 0.9981 - val_recall: 0.9941 - val_auc: 0.9996\n",
      "Epoch 151/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0048 - accuracy: 0.9961 - precision: 0.9981 - recall: 0.9941 - auc: 0.9996 - val_loss: 0.0182 - val_accuracy: 0.9962 - val_precision: 0.9981 - val_recall: 0.9941 - val_auc: 0.9996\n",
      "Epoch 152/200\n",
      "91459/91459 [==============================] - 9s 93us/step - loss: 0.0047 - accuracy: 0.9962 - precision: 0.9981 - recall: 0.9941 - auc: 0.9996 - val_loss: 0.0214 - val_accuracy: 0.9962 - val_precision: 0.9981 - val_recall: 0.9941 - val_auc: 0.9996\n",
      "Epoch 153/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0049 - accuracy: 0.9962 - precision: 0.9981 - recall: 0.9941 - auc: 0.9996 - val_loss: 0.0163 - val_accuracy: 0.9962 - val_precision: 0.9981 - val_recall: 0.9941 - val_auc: 0.9996\n",
      "Epoch 154/200\n",
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0049 - accuracy: 0.9962 - precision: 0.9981 - recall: 0.9941 - auc: 0.9996 - val_loss: 0.0182 - val_accuracy: 0.9962 - val_precision: 0.9981 - val_recall: 0.9942 - val_auc: 0.9996\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91459/91459 [==============================] - 9s 95us/step - loss: 0.0050 - accuracy: 0.9962 - precision: 0.9981 - recall: 0.9942 - auc: 0.9996 - val_loss: 0.0136 - val_accuracy: 0.9962 - val_precision: 0.9981 - val_recall: 0.9942 - val_auc: 0.9996\n",
      "Epoch 156/200\n",
      "91459/91459 [==============================] - 9s 99us/step - loss: 0.0047 - accuracy: 0.9962 - precision: 0.9981 - recall: 0.9942 - auc: 0.9996 - val_loss: 0.0183 - val_accuracy: 0.9962 - val_precision: 0.9981 - val_recall: 0.9942 - val_auc: 0.9996\n",
      "Epoch 157/200\n",
      "91459/91459 [==============================] - 9s 93us/step - loss: 0.0049 - accuracy: 0.9963 - precision: 0.9982 - recall: 0.9942 - auc: 0.9996 - val_loss: 0.0258 - val_accuracy: 0.9963 - val_precision: 0.9982 - val_recall: 0.9942 - val_auc: 0.9996\n",
      "Epoch 158/200\n",
      "91459/91459 [==============================] - 9s 98us/step - loss: 0.0048 - accuracy: 0.9963 - precision: 0.9982 - recall: 0.9942 - auc: 0.9996 - val_loss: 0.0154 - val_accuracy: 0.9963 - val_precision: 0.9982 - val_recall: 0.9942 - val_auc: 0.9996\n",
      "Epoch 159/200\n",
      "91459/91459 [==============================] - 9s 97us/step - loss: 0.0049 - accuracy: 0.9963 - precision: 0.9982 - recall: 0.9942 - auc: 0.9996 - val_loss: 0.0177 - val_accuracy: 0.9963 - val_precision: 0.9982 - val_recall: 0.9942 - val_auc: 0.9996\n",
      "Epoch 160/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0048 - accuracy: 0.9963 - precision: 0.9982 - recall: 0.9943 - auc: 0.9996 - val_loss: 0.0188 - val_accuracy: 0.9963 - val_precision: 0.9982 - val_recall: 0.9943 - val_auc: 0.9996\n",
      "Epoch 161/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0046 - accuracy: 0.9963 - precision: 0.9982 - recall: 0.9943 - auc: 0.9996 - val_loss: 0.0165 - val_accuracy: 0.9963 - val_precision: 0.9982 - val_recall: 0.9943 - val_auc: 0.9996\n",
      "Epoch 162/200\n",
      "91459/91459 [==============================] - 8s 90us/step - loss: 0.0048 - accuracy: 0.9963 - precision: 0.9982 - recall: 0.9943 - auc: 0.9996 - val_loss: 0.0191 - val_accuracy: 0.9963 - val_precision: 0.9982 - val_recall: 0.9943 - val_auc: 0.9996: 0.9963 - precision: 0.9982 - r\n",
      "Epoch 163/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0049 - accuracy: 0.9964 - precision: 0.9982 - recall: 0.9943 - auc: 0.9996 - val_loss: 0.0194 - val_accuracy: 0.9964 - val_precision: 0.9982 - val_recall: 0.9943 - val_auc: 0.9996\n",
      "Epoch 164/200\n",
      "91459/91459 [==============================] - 8s 92us/step - loss: 0.0047 - accuracy: 0.9964 - precision: 0.9982 - recall: 0.9943 - auc: 0.9996 - val_loss: 0.0245 - val_accuracy: 0.9964 - val_precision: 0.9982 - val_recall: 0.9943 - val_auc: 0.9996\n",
      "Epoch 165/200\n",
      "91459/91459 [==============================] - 9s 93us/step - loss: 0.0048 - accuracy: 0.9964 - precision: 0.9982 - recall: 0.9943 - auc: 0.9996 - val_loss: 0.0195 - val_accuracy: 0.9964 - val_precision: 0.9982 - val_recall: 0.9943 - val_auc: 0.9996\n",
      "Epoch 166/200\n",
      "91459/91459 [==============================] - 8s 92us/step - loss: 0.0049 - accuracy: 0.9964 - precision: 0.9982 - recall: 0.9943 - auc: 0.9996 - val_loss: 0.0213 - val_accuracy: 0.9964 - val_precision: 0.9982 - val_recall: 0.9943 - val_auc: 0.9996\n",
      "Epoch 167/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0049 - accuracy: 0.9964 - precision: 0.9982 - recall: 0.9943 - auc: 0.9996 - val_loss: 0.0253 - val_accuracy: 0.9964 - val_precision: 0.9982 - val_recall: 0.9944 - val_auc: 0.9996\n",
      "Epoch 168/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0047 - accuracy: 0.9964 - precision: 0.9982 - recall: 0.9944 - auc: 0.9996 - val_loss: 0.0223 - val_accuracy: 0.9964 - val_precision: 0.9982 - val_recall: 0.9944 - val_auc: 0.9996\n",
      "Epoch 169/200\n",
      "91459/91459 [==============================] - 8s 92us/step - loss: 0.0048 - accuracy: 0.9965 - precision: 0.9982 - recall: 0.9944 - auc: 0.9996 - val_loss: 0.0190 - val_accuracy: 0.9965 - val_precision: 0.9982 - val_recall: 0.9944 - val_auc: 0.9996\n",
      "Epoch 170/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0048 - accuracy: 0.9965 - precision: 0.9982 - recall: 0.9944 - auc: 0.9996 - val_loss: 0.0295 - val_accuracy: 0.9965 - val_precision: 0.9982 - val_recall: 0.9944 - val_auc: 0.9996\n",
      "Epoch 171/200\n",
      "91459/91459 [==============================] - 8s 93us/step - loss: 0.0048 - accuracy: 0.9965 - precision: 0.9982 - recall: 0.9944 - auc: 0.9996 - val_loss: 0.0247 - val_accuracy: 0.9965 - val_precision: 0.9982 - val_recall: 0.9944 - val_auc: 0.9996\n",
      "Epoch 172/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0049 - accuracy: 0.9965 - precision: 0.9982 - recall: 0.9944 - auc: 0.9996 - val_loss: 0.0212 - val_accuracy: 0.9965 - val_precision: 0.9982 - val_recall: 0.9944 - val_auc: 0.9996\n",
      "Epoch 173/200\n",
      "91459/91459 [==============================] - 8s 92us/step - loss: 0.0047 - accuracy: 0.9965 - precision: 0.9982 - recall: 0.9944 - auc: 0.9996 - val_loss: 0.0155 - val_accuracy: 0.9965 - val_precision: 0.9982 - val_recall: 0.9944 - val_auc: 0.9996\n",
      "Epoch 174/200\n",
      "91459/91459 [==============================] - 9s 96us/step - loss: 0.0048 - accuracy: 0.9965 - precision: 0.9982 - recall: 0.9944 - auc: 0.9997 - val_loss: 0.0178 - val_accuracy: 0.9965 - val_precision: 0.9982 - val_recall: 0.9944 - val_auc: 0.9996\n",
      "Epoch 175/200\n",
      "91459/91459 [==============================] - 8s 91us/step - loss: 0.0047 - accuracy: 0.9965 - precision: 0.9982 - recall: 0.9944 - auc: 0.9997 - val_loss: 0.0181 - val_accuracy: 0.9965 - val_precision: 0.9982 - val_recall: 0.9945 - val_auc: 0.9996\n",
      "Epoch 176/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0050 - accuracy: 0.9965 - precision: 0.9982 - recall: 0.9945 - auc: 0.9997 - val_loss: 0.0228 - val_accuracy: 0.9966 - val_precision: 0.9982 - val_recall: 0.9945 - val_auc: 0.9997\n",
      "Epoch 177/200\n",
      "91459/91459 [==============================] - 9s 94us/step - loss: 0.0047 - accuracy: 0.9966 - precision: 0.9982 - recall: 0.9945 - auc: 0.9997 - val_loss: 0.0233 - val_accuracy: 0.9966 - val_precision: 0.9982 - val_recall: 0.9945 - val_auc: 0.9997\n",
      "Epoch 178/200\n",
      "91459/91459 [==============================] - 9s 100us/step - loss: 0.0046 - accuracy: 0.9966 - precision: 0.9982 - recall: 0.9945 - auc: 0.9997 - val_loss: 0.0192 - val_accuracy: 0.9966 - val_precision: 0.9982 - val_recall: 0.9945 - val_auc: 0.9997\n",
      "Epoch 179/200\n",
      "91459/91459 [==============================] - 8s 91us/step - loss: 0.0047 - accuracy: 0.9966 - precision: 0.9982 - recall: 0.9945 - auc: 0.9997 - val_loss: 0.0149 - val_accuracy: 0.9966 - val_precision: 0.9982 - val_recall: 0.9945 - val_auc: 0.9997\n",
      "Epoch 180/200\n",
      "91459/91459 [==============================] - 8s 89us/step - loss: 0.0046 - accuracy: 0.9966 - precision: 0.9982 - recall: 0.9945 - auc: 0.9997 - val_loss: 0.0215 - val_accuracy: 0.9966 - val_precision: 0.9982 - val_recall: 0.9945 - val_auc: 0.9997\n",
      "Epoch 181/200\n",
      "91459/91459 [==============================] - 8s 90us/step - loss: 0.0046 - accuracy: 0.9966 - precision: 0.9982 - recall: 0.9945 - auc: 0.9997 - val_loss: 0.0220 - val_accuracy: 0.9966 - val_precision: 0.9982 - val_recall: 0.9945 - val_auc: 0.9997\n",
      "Epoch 182/200\n",
      "91459/91459 [==============================] - 8s 90us/step - loss: 0.0046 - accuracy: 0.9966 - precision: 0.9982 - recall: 0.9945 - auc: 0.9997 - val_loss: 0.0150 - val_accuracy: 0.9966 - val_precision: 0.9982 - val_recall: 0.9945 - val_auc: 0.9997\n",
      "Epoch 183/200\n",
      "91459/91459 [==============================] - 8s 88us/step - loss: 0.0044 - accuracy: 0.9966 - precision: 0.9982 - recall: 0.9946 - auc: 0.9997 - val_loss: 0.0184 - val_accuracy: 0.9966 - val_precision: 0.9982 - val_recall: 0.9946 - val_auc: 0.9997\n",
      "Epoch 184/200\n",
      "91459/91459 [==============================] - 8s 88us/step - loss: 0.0047 - accuracy: 0.9966 - precision: 0.9982 - recall: 0.9946 - auc: 0.9997 - val_loss: 0.0228 - val_accuracy: 0.9967 - val_precision: 0.9982 - val_recall: 0.9946 - val_auc: 0.9997\n",
      "Epoch 185/200\n",
      "91459/91459 [==============================] - 8s 85us/step - loss: 0.0046 - accuracy: 0.9967 - precision: 0.9982 - recall: 0.9946 - auc: 0.9997 - val_loss: 0.0191 - val_accuracy: 0.9967 - val_precision: 0.9982 - val_recall: 0.9946 - val_auc: 0.9997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/200\n",
      "91459/91459 [==============================] - 8s 88us/step - loss: 0.0045 - accuracy: 0.9967 - precision: 0.9982 - recall: 0.9946 - auc: 0.9997 - val_loss: 0.0229 - val_accuracy: 0.9967 - val_precision: 0.9982 - val_recall: 0.9946 - val_auc: 0.9997\n",
      "Epoch 187/200\n",
      "91459/91459 [==============================] - 8s 85us/step - loss: 0.0046 - accuracy: 0.9967 - precision: 0.9982 - recall: 0.9946 - auc: 0.9997 - val_loss: 0.0242 - val_accuracy: 0.9967 - val_precision: 0.9983 - val_recall: 0.9946 - val_auc: 0.9997\n",
      "Epoch 188/200\n",
      "91459/91459 [==============================] - 8s 88us/step - loss: 0.0045 - accuracy: 0.9967 - precision: 0.9983 - recall: 0.9946 - auc: 0.9997 - val_loss: 0.0196 - val_accuracy: 0.9967 - val_precision: 0.9983 - val_recall: 0.9946 - val_auc: 0.9997 0.0046 - accuracy: 0.9967 - precision: 0.9983 - recall: 0.9946\n",
      "Epoch 189/200\n",
      "91459/91459 [==============================] - 8s 85us/step - loss: 0.0045 - accuracy: 0.9967 - precision: 0.9983 - recall: 0.9946 - auc: 0.9997 - val_loss: 0.0198 - val_accuracy: 0.9967 - val_precision: 0.9983 - val_recall: 0.9946 - val_auc: 0.9997\n",
      "Epoch 190/200\n",
      "56704/91459 [=================>............] - ETA: 2s - loss: 0.0045 - accuracy: 0.9967 - precision: 0.9983 - recall: 0.9946 - auc: 0.9997"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=neural_network)\n",
    "estimator.fit(X_train,Y_train,verbose=1,callbacks=[early_stopping], epochs=200,validation_split=0.2, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76216/76216 [==============================] - 18s 242us/step - loss: 0.1045 - accuracy: 0.9966 - precision: 0.9980 - recall: 0.9946 - auc: 0.9997\n",
      "Epoch 1/1\n",
      "76216/76216 [==============================] - 18s 230us/step - loss: 0.1093 - accuracy: 0.9965 - precision: 0.9980 - recall: 0.9943 - auc: 0.9997\n",
      "Cross-Validation set accuracy: 97.794864 %\n",
      "114324/114324 [==============================] - 9s 76us/step\n",
      "Train set accuracy           : 99.6564 %\n",
      "Test set accuracy            : 80.1723 %\n",
      "Test set precision : 0.9695\n",
      "Test set recall    : 0.6725\n",
      "Test set F1-score  : 0.7941\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross-Validation set accuracy: {:.6f} %\".format((cross_val_score(estimator, X_train, Y_train, \n",
    "                                                                        cv=3,scoring='accuracy').mean())*100))\n",
    "test_predictions = estimator.predict(X_test)\n",
    "print(\"Train set accuracy           : {:.4f} %\".format(estimator.score(X_train,Y_train)*100))\n",
    "print(\"Test set accuracy            : {:.4f} %\".format(accuracy_score(Y_test, test_predictions)*100))\n",
    "print(\"Test set precision : {:.4f}\".format(precision_score(Y_test, test_predictions)))\n",
    "print(\"Test set recall    : {:.4f}\".format(recall_score(Y_test, test_predictions)))\n",
    "print(\"Test set F1-score  : {:.4f}\".format(f1_score(Y_test, test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives  : 0.97\n",
      "False Positives : 0.03\n",
      "False Negatives : 0.33\n",
      "True Positives  : 0.67\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMAAAACaCAYAAAD/yUeWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAZMUlEQVR4nO2dd3xUVfbAvyeTEFqowVCUpiACimAoIooF/IEoNlzEuipSLKtYEF0bdtd1kbUBguAuLiiKq7KAgoWioBQVAwgihhIRCAktlEw5vz/eyzCTmUwmY2Ymydzv53M/ee++e+87L/POu+e2c0VVMRgSlaR4C2AwxBOjAIaExiiAIaExCmBIaIwCGBIaowCGhCY53gKUhDN3c5Xun63R9Ox4ixBVXIU5UtK1YL9tSnrrEtNHkwqrAIYqjNsZbwm8GAUwxBx1u+ItghejAIbYYxTAkNA4j8ZbAi9GAQwxx5hAhsTGNIINCY2rMN4SeDEKYIg5amoAQ0JjagBDQmNqAENCY3qBDImMmnEAQ0JjagBDQmMUwJDQOCtOL5BZEGOIPW5XYAgDEeknIhtEZJOIjAlyva6IfCwiP4jIWhG5qbQyjQIYYk8ECiAiDuBVoD/QHhgiIu2LJbsdWKeqnYBzgRdFpFqoco0JZIg9kZlA3YBNqroZQERmApcC63zSKJAmIgLUBvKAkNplFMAQe9zuSHI1A7b5nG8HuhdL8wrwEfAbkAYMVlVPqEKNCWSIPS5XQBCRYSKy0icMK5Yr2Jrh4muL/w/4HmgKnA68IiJ1QolSJRVg5uw5/N+gP9PlvIH86eY7WfV9Vsj08z9bzJU33k7m+ZfR94obefPt9/yu//WpF+l4Vv+A0PWCy6L5GCUyYviN/LxhGQf3/8I3y+fR66xuIdN37NiOzxe+x4F9m9jy60oe/uvdftfPObsHSxZ9yM4dWRzYt4msHxdxz6jh0XsAlzMgqOokVc30CZOK5doOnOBzfjzWl96Xm4DZarEJ+BVoF0qUKmcCzVu4iOdemsDD991O59M68M7sOYy47xE+mj6RJo2PC0i/ZNkKHhj7PA/ePZKzup/B5i3bePy58VRPrcY1gwYCMObuEYwa6d+hcN2Ie8k8/dSYPJMvV101kHH/GMsddz7EV19/y4jhNzLn4+mc2ulctm0r/j5AWlpt5s+dwZKl39Cj5wDatj2RNyePo6DgMONemgjAwYMFvPzqFLKyfuLQocP07NmV1199nkOHjjBh4lvl/xCuiMYBVgBtRKQVkANcDVxTLM1W4AJgiYhkACcDm0MVKhXVO3SkblGG3Ho3bU9sxdgxd3njLhp8C33P7RXwEgOMfvx5jhw9yj+ffdQb9/asD3nzP++xcPa/sNpT/qxes5YbRt7Hvye8SOdTi3dEhEekblG+Xvoxa35cz4iRo71x69cuZfYHc/jrw88FpB8+7AaefeYhmh5/OkeOHAHgoQfvYviw62nRKrPE+8x69w2OHi3kuutvj0jOUG5RDk0aFfDb1hw2rlS3KCJyEfAS4ADeVNWnRWQEgKpOEJGmwDSgCZbJ9JyqTg9VZpUygZxOJ+s2/EzPbl384nt268IPWeuC5iksdJJazb+nLDU1lZ27cvnt911B87z/0XxOatUi4pc/UlJSUujS5TQWLFzsF79g4SLO7BH8Ze7R4wyWLv3W+/IDfPrplzRr1oSWLU8Imuf00ztwZo9MFi9eXn7C++J0BoYwUNW5qtpWVU9U1aftuAmqOsE+/k1VL1TVU1W1Y2kvP0RRAUSknYg8ICL/FJHx9vEp0bofQP7e/bjdHho2qOcX37B+PXL35AfNc1b3Lny+eBlffbMKj8dD9tbtvDVzNgC79+QFpD9wsIBPv1jClQP7lf8DlEJ6egOSk5PZtXO3X/yuXbvJCGLeATTOaMTOXf7pi84bZ/jnyd68koIDm/lm2TwmTHyLSW/8uxyl9yFIIzheRKUNICIPAEOAmcC3dvTxwAwRmamqgXV1ed6/WIeBWjIFTTtoYH+25ezgL2OewOV2UatmTa7702W8NmU6jqTA78OcTz7H7fEwsN8F0RA9LIqbrSISEFda+mDx555/ObVr16J7ty48+8xD/Jq9jbfffr+cpPbBWQnmAonIAY51MxW9PWofq6qG6l66Beigqn51m4j8A1gLBFUAu+trGMBrLz7F0BuGhPMMXurXq4PDkURunv/XPi9/b0Ct4HNP7rntFu4a/mdy8/JpUK8uy1d+D0DTJhkB6d/7aD59e59F3TppZZKtPMjNzcPlcgV87Rs1Sg+oFYr4fefugC/9cY3SAQJqhuxsq5s9K+snMjIa8ejD90RHASIbB4gKJZpAqpqmqnXskOZznlbKyw/gweqLLU4T+1pJ9/R2hZX15QfLRm5/chuWrVjtF79sxXd06hjaXnc4HGQ0SiclJYW5CxfRqeMpNKzvrzRr1v7Ehk2buXJg/zLLVh44nU5Wr15Dnwv8G9B9+pzDsuUrg+ZZvnwVvXp1IzU11S99Ts4O7wsfjKQk8ctTnqjLHRDiRVgmkIj0Atqo6lQRSQfSVPXXEFnuBj4TkZ85NnrXHDgJuOOPCFwaNwy+nAef/DsdTzmZzqe1593/zmVX7h4GX34RAONen0rW+g1M+adVCeXv3ccnXyyha+fTcBY6+WDuAj79fAnTXv1bQNnvfTSfFic0o2vn2Hd/FjFu/Bu8NXU8K1Z8z9fLVjDs1utp2iSDiZMse/3pp8bQNbMzF/YbDMCMmR/wyMOjeHPKOJ55djxt2rRm9P238+RT47xl3n7bTWRnb2PDxl8AOLtXd+4ZNSI6XaAQdqM3FpSqACLyGJCJ1ac6FagGTAfOKimPqs4XkbZY8zeaYZlN24EVqhpVde/fpzf79h9g0lsz2L0njzatW/L635+gaWPLnMndk8e2nB1+eT6e9xkvvjoFVOnU8RSmvvI8p7Y/2S9NQcEh5n22iJE3XVNieyIWzJr1EQ0b1OehB++iSZPjyFq7gUsGXs/WrTkANG6cQevWLbzp9+8/QL+LhvDy+Kf5Ztlc8vP3Me6lid4xALBqv2eeeYiWLU7A5XLxy+YtPPTXZ5k46V/ReYgKZAKVOg4gIt8DnYHVqtrZjlujqqdFUzDjHr1yE2oc4OCDVwb8trWffb/CukcvVFUVEQUQkVpRlslQ1alAvUDhjAO8KyITgXoiciuwEHgjumIZqjLq8gSEeFFqDaCqfxeRvsB+oC3wqKouiLpkhqpLHHt9ihPuQNiPQA2scYAfoyeOIRFQZ8VRgFJNIBEZijWaewUwCFguIjdHWzBDFcblCQxxIpwa4H6gs6ruARCRhsDXwJvRFMxQdYmnzV+ccBRgO3DA5/wA/kvTDIYyoYWVQAFE5B77MAf4RkQ+xGoDXMqxCW4GQ5lRV2RDPCLSDxiPtR5gcrBJlSJyLtaagRQgV1V7hyozVA1QNNvrFzsU8WEZZDYYAtDCsiuAj1uUvtizCkTkI1Vd55OmHvAa0E9Vt4pI8DniPpSoAKo6tsxSGgxhoJGNg4XjFuUarDXBWwFUNfiKJh/CmQvUCBgNdACqF8Wr6vllkd5gKCJCBQjHLUpbIEVEvsSyYMarasgJTeGMBL8N/AS0AsYC2VgLlA2GiHAXBoZycouSDJwBDMBykfKIPSmzRMLpBWqoqlNE5C5VXQQsEpFFYeQzGIKi7sB32XaDUtwVii/huEXZjtXwLQAKRGQx0AnYWFKh4dQARZO3d4jIABHpbN/cYIgIj0sCQhh43aLY/j6vxvIC58uHwNkikiwiNbFMpPWhCg2nBnhKROoC9wIvA3WAUeFIbDAEw+0suy8GVXWJyB3AJxxzi7LW1y2Kqq4XkfnAGqyVh5NVNaRXtCrnF6iykMjrAbZ06RPw27ZYvbBirQcQkZcJbGR4UdW/REUiQ5XHE6QNEC9CmUDBV1kbDH+QSEygaBFqICxKK6INiY7bUwkUwGCIFpXFBDIYooLL5Yi3CF6MAhhijttTCWqAePcCPZn5SDSLjzv5N8fPuVa88VQGBcD0AhmihNNdCUwg0wtkiBZurRw1AOCdDv0A1t6sZjq04Q/j0orTDRrudOj1mOnQhnLCpRIQ4kU4CtBQVacATlVdpKo3Az2iLJehCuNGAkK8CKcb1G86NNYcbDMd2hAxzji+8MUx06ENMccdR/fyxSnVBFLVOaq6T1WzVPU8VT1DVYsvRDAYwiZSE0hE+onIBhHZJCJjQqTrKiJuERlUWpnh9AJNJciAmN0WMBjKjDOCGiActyg+6Z7HWjhTKuGYQHN8jqsDlxO4FtNgCJvwVkAGEI5bFIA7gfeBruEUGo57dL9tAkVkBtYeAQZDRETY61OqWxQRaYb1gT6fMBUgkhGJNlgb3hkMEeGUwFBOblFeAh4oyz504bQBfPcLBvgda2TYYIiIYCZQOblFyQRm2psYpgMXiYhLVf9bUqHhmECx3xHaUKWJcD2M1y0KlsPmq7FcIXpR1VZFxyIyDZgT6uWH8DbI+CycOIMhXJxBQmmoqgtrj+lPsKbmvFvkFqXINUokhFoPUB2oCaSLSH2O2WB1CL4LvMEQFhH2AqGqc4G5xeImlJD2z+GUGcoEGo6143tTYBXHFGA/Vn+swRARFWeHsNDrAcYD40XkTlV9OYYyGao4zoozEyKsblCPvfEAACJSX0Rui6JMhiqOCw0I8SIcBbhVVfcWnahqPnBr9EQyVHWCjQPEi3CmQiSJiKjtRNSea1EtumIZqjLuOH7xixOOAnwCvCsiE7AGxEYA86Mq1R+k63V96DV8ALWPq8fujTnMe+LfbFmxIWjaRic14+In/0yjk5qRWqcGB3buJevjZXzx0vu47Q2dW3ZvR5/Rg0lv3YSUGqnszcll9cwv+OqNuUHLjDYpvS+mWt9BSN0GeH7bwtFZE3BvWhs6z/mXkXLOAJIaZqCHDuJctoDC/04FoPqN95JyZt+APHr0CAfvuqzc5Y+nyVOccBTgAWAYMBKrJ+hT4I1oCvVH6HhxDy567HrmPDKNLSs20O36Plw3bTSv9B3Nvt/2BKR3O1189/4SdqzN5sj+QzQ+pTmXPjuUJIeDT5+bAcDRgiMsn/YJO3/ahvNwIc0z2zLwmZspPFzIiumxnRaVfMY5pP5pBEdnvIJ701pSel9MjTueomDsMDR/d9A8qYOGkXxqN47Onow7JxupUQup28B7/cg7r3P0A/9tn2ve/yLun0N6Fo8YZ2VSAFX1ABPsgIj0wloYc3t0RYuMnkP78917S1g18wsA5j7+L9r07kTX6/qw8G/vBKTP27KTvC07vef7cnJZ0+MrWnQ72Ru3IyubHVnZ3vO923fTvl9XWnQ7OeYKUK3PFTiXLcC51KqEj77zOskdMknpfbH3i+6LZBxPynkDOfTkSDy/W3PJFGCbz8afRw6hRw55Tx0ntiepUVMOT30hKs9QkbpBw5oMJyKni8jzIpINPIm1Z1iFw5HioEnHVvyyZI1f/KYlP9L8jDZhldGgRQYn9e5E9jclbyzSuEMLTjijDdnfxPjf4EgmqXkb3OtW+0W71q3G0fqUoFlSOvVAd/+Oo0MmtZ6cSq2n36L6jfciaXVLvE1Kr/64c7LxbA65uUrEuNGAEC9CjQS3xZpvMQTYA7yDtaHGeX/khiJyk6oGfqrKgZr103AkOziYu98vviB3H7XP6hAy79D3H6NJx5akpFZj5X8+Z+Hf3g1Ic++yl6nVII2kZAdfjp/NyrdjOyNEatdBHA50f75fvO7PJ6ld5+B50psgDY8jJbM3R956EVBSr7yVGreN5dDfRkHxDVKq1yS5y9kc/TAqPxEATirBTvFYX/klwCWquglARMpjLfBYIHr/XQj8UUVK/ca8e8fLpNaqQeP2zbnwwWvoNfISlrzmv/JzylVPUK1WdU7ofBJ9x1xN/rbd/PDB0vKVPSyCPV8JTyiCpFTj8NQX0F05ABye+gK1n5hCUou2eLL9OwdSul8ASUk4l0dPuStLL9CVWDXAF/a+SzMJPic7ABFZU9IlICNEvmFYDW4GNOhGl7STwrmdl0P5B3C73NRu5F+912pYh4LcfSHz7t+RB8DuTTlIUhKXPj+UrybOweM+9rXau91qZO7asI3a6XU57+4rYqoAenA/6nYjdRr4xUtavYBawZtnXx7qdnlffgDdlYO6XSQ1OC5QAXr1w/XdUjh0sPwfwKYiKUCJbQBV/UBVBwPtgC+xPEFkiMjrInJhKeVmADcAlwQJgV0xx+45SVUzVTWzrC8/gNvpZkfWr5zYy9/x7Im9OrJ11c9hlyNJQpLDgThKbiJJkuCollJmGf8QbheerT/jOMXf3Ek+pTPuEux19y/rEEcykt7EGyfpTRBHMp68nX5pk1qejOOEE70N7GjhVA0I8SKcXqACLO9wb4tIA+AqYAxWd2hJzAFqq+r3xS/Yu3hHja8nz+OKf4xk+w+/sHXlRrpedwFpGfVZYdvrfUYP5vhOrZl27bMAdLq8F66jhezcsA13oYump7Wm7+jBrJv3Le5Ca0vz7jdeSP623eRuttZftOzWjp63DmDF9AXRfJSgFC6cTfWb7seTvRH3L2tJOWcAUrchzsX/A6DaZTfhaNmWwy89CID7p+9wb/mZ6jeM4uisiQCkXjUc9+b1eLb4fxRSevXHs3M77o0lVeDlg7uStAECUNU8YKIdQqW7JcS1a0q6Vh5kzVlOjXq16X3nZaQ1qseujduZftML7MvJBSDtuHrUb3HMCvO43Zx920AatmwMIuzLyeXbfy3g6ynzvGmSHElcOOZq6h2fjsflIW/rThY8PzPmjWAA16rFHK1dh2oXDUHq1Mfz2xYOv/IImrfLkrVuA5Ia+cxWV+Xwq4+ROngkNe99AS0sxP3Tao7MmuTfVkqtQUpmbwrnvh39Z4jQBBKRfsB4rG1SJ6vqc8WuX8ux1YoHgZGq+kPIMivqNqmPtry2YgpWTtzfr0RLsEqQNmF+ie3Fy5tfEvDbfrD145DtS3sKzkZ83KIAQ3zdoohIT2C9quaLSH/gcVXtHrRAG7NDjCHmRFgDlOoWRVW/9km/nDBceBoFMMQcV/hOG3wp1S1KMW4B5oW4DhgFMMSBYN2gvl3gNpNsTxHeJEGKClqViMh5WArQqzRZjAIYYo5bA3uBysktCiJyGjAZ6K+qpTa0jAIYYo4zMhOoVLcoItIcmA1cr6obwynUKIAh5kQyEqyqLhEpcoviAN4scotiX58APAo0BF6znWO5VDUzVLlGAQwxJ5gJFA6luUVR1aHA0LKUaRTAEHMi7AWKCkYBDDEn0hogGhgFMMScSjsXyGAoD5weYwIZEhhjAhkSGqMAhoTGpa54i+DFKIAh5pgawJDQuD1GAQwJjBkIMyQ0pgYwJDQuMw5gSGRMI9iQ0BgTyJDQuCuQCVRh3aLEGhEZVmwNapWiqj9fpITlHj1BGFZ6kkpNVX++iDAKYEhojAIYEhqjAMeo6vZxVX++iDCNYENCY2oAQ0JjFADL7baIbBCRTSIyJt7ylCci8qaI7BKR6Ox5WslJeAWw3W6/CvQH2gNDRKR9fKUqV6YB/eItREUl4RUAH7fbqlqItRfapXGWqdxQ1cVAXrzlqKgYBQjudrtZnGQxxBijAGVwu22oehgFCNPttqFqYhTAx+22iFTDcrv9USl5DFWEhFcAVXUBRW631wPvqura+EpVfojIDGAZcLKIbBeREnfwTETMSLAhoUn4GsCQ2BgFMCQ0RgEMCY1RAENCYxTAkNAkjAKIiFtEvheRLBGZJSI1/0BZ00RkkH08OdTkORE5V0R6RnCPbBFJDze+WJqDZbzX4yJyX1llrAokjAIAh1X1dFXtCBQCI3wv2rNCy4yqDlXVdSGSnAuUWQEMsSGRFMCXJcBJ9tf5CxH5D/CjiDhE5AURWSEia0RkOIBYvCIi60Tkf8BxRQWJyJcikmkf9xOR1SLyg4h8JiItsRRtlF37nC0ijUTkffseK0TkLDtvQxH5VES+E5GJBJ+j5IeI/FdEVonIWhEZVuzai7Ysn4lIIzvuRBGZb+dZIiLtyuOfWalR1YQIwEH7bzLwITAS6+tcALSyrw0DHraPU4GVQCvgCmAB1gbNTYG9wCA73ZdAJtAIa1ZpUVkN7L+PA/f5yPEfoJd93BxYbx//E3jUPh6ANSEvPchzZBfF+9yjBpAFNLTPFbjWPn4UeMU+/gxoYx93Bz4PJmMihUTyDFdDRL63j5cAU7BMk29V9Vc7/kLgtCL7HqgLtAHOAWaoqhv4TUQ+D1J+D2BxUVmqWtIc/D5Ae3snc4A6IpJm3+MKO+//RCQ/jGf6i4hcbh+fYMu6B/AA79jx04HZIlLbft5ZPvdODeMeVZpEUoDDqnq6b4T9IhT4RgF3quonxdJdROlTpCWMNGCZnWeq6uEgsoQ9L0VEzsVSpjNV9ZCIfAlULyG52vfdW/x/kOgkahugJD4BRopICoCItBWRWsBi4Gq7jdAEOC9I3mVAbxFpZedtYMcfANJ80n2KNfkOO13RC7kYuNaO6w/UL0XWukC+/fK3w6qBikgCimqxa4Clqrof+FVErrLvISLSqZR7VHmMAvgzGVgHrLYXkU/EqiU/AH4GfgReBxYVz6iqu7HaELNF5AeOmSAfA5cXNYKBvwCZdiN7Hcd6o8YC54jIaixTbGspss4HkkVkDfAksNznWgHQQURWAecDT9jx1wK32PKtpQot/YwUMxvUkNCYGsCQ0BgFMCQ0RgEMCY1RAENCYxTAkNAYBTAkNEYBDAmNUQBDQvP/mO1NLSO3iGUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 180x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_cm(labels, predictions):\n",
    "    cm = confusion_matrix(labels, predictions, normalize= 'true')\n",
    "    plt.figure(figsize=(2.5,2))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".2f\",annot_kws={'size':14})\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    print('True Negatives  : {:.2f}'.format(cm[0][0]))\n",
    "    print('False Positives : {:.2f}'.format(cm[0][1]))\n",
    "    print('False Negatives : {:.2f}'.format(cm[1][0]))\n",
    "    print('True Positives  : {:.2f}'.format(cm[1][1]))\n",
    "    \n",
    "plot_cm(Y_test,test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.81      9711\n",
      "           1       0.97      0.67      0.79     12803\n",
      "\n",
      "    accuracy                           0.80     22514\n",
      "   macro avg       0.83      0.82      0.80     22514\n",
      "weighted avg       0.85      0.80      0.80     22514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, test_predictions.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sharuka thirimanne\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr_lr, tpr_lr, _ = roc_curve(Y_test, test_predictions)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlim([-0.01, 1.00])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.plot(fpr_lr, tpr_lr, lw=3, label='KNN ROC curve (area = {:0.2f})'.format(roc_auc_lr))\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('ROC curve', fontsize=18)\n",
    "plt.legend(loc='lower right', fontsize=18)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'build_fn': <function __main__.neural_network(optimizer='sgd', init='glorot_uniform')>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n",
      "[CV] batch_size=32, nb_epoch=50 ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 12s 212us/step - loss: 0.0127 - accuracy: 0.9965 - precision: 0.9978 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ....................... batch_size=32, nb_epoch=50, total=  18.4s\n",
      "[CV] batch_size=32, nb_epoch=50 ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   18.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 12s 214us/step - loss: 0.0206 - accuracy: 0.9965 - precision: 0.9978 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ....................... batch_size=32, nb_epoch=50, total=  18.8s\n",
      "[CV] batch_size=32, nb_epoch=100 .....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 12s 210us/step - loss: 0.0152 - accuracy: 0.9965 - precision: 0.9978 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ...................... batch_size=32, nb_epoch=100, total=  18.6s\n",
      "[CV] batch_size=32, nb_epoch=100 .....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 12s 205us/step - loss: 0.0162 - accuracy: 0.9965 - precision: 0.9978 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ...................... batch_size=32, nb_epoch=100, total=  18.6s\n",
      "[CV] batch_size=32, nb_epoch=150 .....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 12s 212us/step - loss: 0.0145 - accuracy: 0.9965 - precision: 0.9978 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ...................... batch_size=32, nb_epoch=150, total=  18.0s\n",
      "[CV] batch_size=32, nb_epoch=150 .....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 12s 214us/step - loss: 0.0264 - accuracy: 0.9965 - precision: 0.9978 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ...................... batch_size=32, nb_epoch=150, total=  18.8s\n",
      "[CV] batch_size=32, nb_epoch=200 .....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 12s 210us/step - loss: 0.0165 - accuracy: 0.9965 - precision: 0.9978 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ...................... batch_size=32, nb_epoch=200, total=  18.3s\n",
      "[CV] batch_size=32, nb_epoch=200 .....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 12s 210us/step - loss: 0.0164 - accuracy: 0.9965 - precision: 0.9978 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ...................... batch_size=32, nb_epoch=200, total=  18.5s\n",
      "[CV] batch_size=64, nb_epoch=50 ......................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 8s 138us/step - loss: 0.0242 - accuracy: 0.9965 - precision: 0.9978 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ....................... batch_size=64, nb_epoch=50, total=  13.8s\n",
      "[CV] batch_size=64, nb_epoch=50 ......................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 8s 139us/step - loss: 0.0468 - accuracy: 0.9965 - precision: 0.9978 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ....................... batch_size=64, nb_epoch=50, total=  13.6s\n",
      "[CV] batch_size=64, nb_epoch=100 .....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 8s 142us/step - loss: 0.0276 - accuracy: 0.9965 - precision: 0.9978 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ...................... batch_size=64, nb_epoch=100, total=  13.9s\n",
      "[CV] batch_size=64, nb_epoch=100 .....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 8s 137us/step - loss: 0.0461 - accuracy: 0.9965 - precision: 0.9978 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ...................... batch_size=64, nb_epoch=100, total=  13.5s\n",
      "[CV] batch_size=64, nb_epoch=150 .....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 8s 136us/step - loss: 0.0286 - accuracy: 0.9965 - precision: 0.9978 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ...................... batch_size=64, nb_epoch=150, total=  13.5s\n",
      "[CV] batch_size=64, nb_epoch=150 .....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 8s 137us/step - loss: 0.0305 - accuracy: 0.9966 - precision: 0.9978 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ...................... batch_size=64, nb_epoch=150, total=  14.5s\n",
      "[CV] batch_size=64, nb_epoch=200 .....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 8s 136us/step - loss: 0.0267 - accuracy: 0.9966 - precision: 0.9978 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ...................... batch_size=64, nb_epoch=200, total=  13.6s\n",
      "[CV] batch_size=64, nb_epoch=200 .....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 8s 141us/step - loss: 0.0349 - accuracy: 0.9966 - precision: 0.9978 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ...................... batch_size=64, nb_epoch=200, total=  13.6s\n",
      "[CV] batch_size=128, nb_epoch=50 .....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 5s 88us/step - loss: 0.0794 - accuracy: 0.9965 - precision: 0.9977 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ...................... batch_size=128, nb_epoch=50, total=   9.8s\n",
      "[CV] batch_size=128, nb_epoch=50 .....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 5s 84us/step - loss: 0.0736 - accuracy: 0.9965 - precision: 0.9977 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ...................... batch_size=128, nb_epoch=50, total=   9.5s\n",
      "[CV] batch_size=128, nb_epoch=100 ....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 5s 90us/step - loss: 0.0686 - accuracy: 0.9966 - precision: 0.9977 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ..................... batch_size=128, nb_epoch=100, total=   9.8s\n",
      "[CV] batch_size=128, nb_epoch=100 ....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 5s 92us/step - loss: 0.0750 - accuracy: 0.9966 - precision: 0.9977 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ..................... batch_size=128, nb_epoch=100, total=  10.8s\n",
      "[CV] batch_size=128, nb_epoch=150 ....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 5s 87us/step - loss: 0.0508 - accuracy: 0.9966 - precision: 0.9977 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ..................... batch_size=128, nb_epoch=150, total=   9.9s\n",
      "[CV] batch_size=128, nb_epoch=150 ....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 5s 94us/step - loss: 0.0743 - accuracy: 0.9966 - precision: 0.9977 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ..................... batch_size=128, nb_epoch=150, total=  10.2s\n",
      "[CV] batch_size=128, nb_epoch=200 ....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 5s 90us/step - loss: 0.0534 - accuracy: 0.9966 - precision: 0.9977 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ..................... batch_size=128, nb_epoch=200, total=   9.8s\n",
      "[CV] batch_size=128, nb_epoch=200 ....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 5s 85us/step - loss: 0.0791 - accuracy: 0.9966 - precision: 0.9976 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ..................... batch_size=128, nb_epoch=200, total=   9.9s\n",
      "[CV] batch_size=256, nb_epoch=50 .....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 4s 68us/step - loss: 0.1130 - accuracy: 0.9966 - precision: 0.9976 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ...................... batch_size=256, nb_epoch=50, total=   8.2s\n",
      "[CV] batch_size=256, nb_epoch=50 .....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 4s 63us/step - loss: 0.1535 - accuracy: 0.9966 - precision: 0.9976 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ...................... batch_size=256, nb_epoch=50, total=   8.0s\n",
      "[CV] batch_size=256, nb_epoch=100 ....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 4s 71us/step - loss: 0.1179 - accuracy: 0.9966 - precision: 0.9976 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ..................... batch_size=256, nb_epoch=100, total=   9.3s\n",
      "[CV] batch_size=256, nb_epoch=100 ....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 4s 66us/step - loss: 0.1651 - accuracy: 0.9966 - precision: 0.9975 - recall: 0.9943 - auc: 0.9996\n",
      "[CV] ..................... batch_size=256, nb_epoch=100, total=   8.1s\n",
      "[CV] batch_size=256, nb_epoch=150 ....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 4s 68us/step - loss: 0.1016 - accuracy: 0.9965 - precision: 0.9975 - recall: 0.9943 - auc: 0.9995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... batch_size=256, nb_epoch=150, total=   8.1s\n",
      "[CV] batch_size=256, nb_epoch=150 ....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 4s 66us/step - loss: 0.1567 - accuracy: 0.9965 - precision: 0.9975 - recall: 0.9943 - auc: 0.9995\n",
      "[CV] ..................... batch_size=256, nb_epoch=150, total=   8.1s\n",
      "[CV] batch_size=256, nb_epoch=200 ....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 4s 71us/step - loss: 0.0921 - accuracy: 0.9966 - precision: 0.9975 - recall: 0.9943 - auc: 0.9995\n",
      "[CV] ..................... batch_size=256, nb_epoch=200, total=   8.7s\n",
      "[CV] batch_size=256, nb_epoch=200 ....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 4s 70us/step - loss: 0.1334 - accuracy: 0.9966 - precision: 0.9975 - recall: 0.9943 - auc: 0.9995: 5s - loss: 0.4511 - accuracy: 0.9966 - preci\n",
      "[CV] ..................... batch_size=256, nb_epoch=200, total=   8.2s\n",
      "[CV] batch_size=512, nb_epoch=50 .....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 3s 59us/step - loss: 0.1807 - accuracy: 0.9966 - precision: 0.9975 - recall: 0.9943 - auc: 0.9995\n",
      "[CV] ...................... batch_size=512, nb_epoch=50, total=   7.7s\n",
      "[CV] batch_size=512, nb_epoch=50 .....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 3s 60us/step - loss: 0.3312 - accuracy: 0.9965 - precision: 0.9974 - recall: 0.9943 - auc: 0.9995\n",
      "[CV] ...................... batch_size=512, nb_epoch=50, total=   8.5s\n",
      "[CV] batch_size=512, nb_epoch=100 ....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 3s 58us/step - loss: 0.2007 - accuracy: 0.9965 - precision: 0.9974 - recall: 0.9943 - auc: 0.9995\n",
      "[CV] ..................... batch_size=512, nb_epoch=100, total=   8.0s\n",
      "[CV] batch_size=512, nb_epoch=100 ....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 3s 58us/step - loss: 0.3277 - accuracy: 0.9965 - precision: 0.9973 - recall: 0.9943 - auc: 0.9995: 1s - loss: 0.4526 - accuracy: 0.9965 - precision: 0.9973 - recall: 0.994\n",
      "[CV] ..................... batch_size=512, nb_epoch=100, total=   7.3s\n",
      "[CV] batch_size=512, nb_epoch=150 ....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 3s 60us/step - loss: 0.1881 - accuracy: 0.9965 - precision: 0.9972 - recall: 0.9943 - auc: 0.9995\n",
      "[CV] ..................... batch_size=512, nb_epoch=150, total=   8.0s\n",
      "[CV] batch_size=512, nb_epoch=150 ....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 3s 57us/step - loss: 0.2867 - accuracy: 0.9964 - precision: 0.9971 - recall: 0.9943 - auc: 0.9995\n",
      "[CV] ..................... batch_size=512, nb_epoch=150, total=   7.3s\n",
      "[CV] batch_size=512, nb_epoch=200 ....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 3s 58us/step - loss: 0.1929 - accuracy: 0.9964 - precision: 0.9971 - recall: 0.9943 - auc: 0.9995\n",
      "[CV] ..................... batch_size=512, nb_epoch=200, total=   7.9s\n",
      "[CV] batch_size=512, nb_epoch=200 ....................................\n",
      "Epoch 1/1\n",
      "57162/57162 [==============================] - 3s 53us/step - loss: 0.2911 - accuracy: 0.9964 - precision: 0.9970 - recall: 0.9943 - auc: 0.9995: 1s - loss: 0.4776 - accuracy: 0.9964 - precision: 0.9970 - recall: \n",
      "[CV] ..................... batch_size=512, nb_epoch=200, total=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  7.8min finished\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <keras.wrappers.scikit_learn.KerasClassifier object at 0x000001D39CDE35F8>, as the constructor either does not set or modifies parameter batch_size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-898d6a8a7a3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     verbose = 2)\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0moptimal_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimal_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sharuka thirimanne\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sharuka thirimanne\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[1;32m--> 762\u001b[1;33m                 **self.best_params_))\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sharuka thirimanne\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sharuka thirimanne\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     96\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0;32m     97\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                                (estimator, name))\n\u001b[0m\u001b[0;32m     99\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <keras.wrappers.scikit_learn.KerasClassifier object at 0x000001D39CDE35F8>, as the constructor either does not set or modifies parameter batch_size"
     ]
    }
   ],
   "source": [
    "optimizers = ['sgd','rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = np.array([50, 100, 150,200])\n",
    "batches = np.array([32,64,128,256,512])\n",
    "#param_grid = dict(optimizer=optimizers, nb_epoch=epochs, batch_size=batches, init=init)\n",
    "param_grid = dict(nb_epoch=epochs, batch_size=batches)\n",
    "\n",
    "optimal_params = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = param_grid,\n",
    "    cv=2,\n",
    "    scoring ='accuracy',\n",
    "    verbose = 2)\n",
    "optimal_params.fit(X_train,Y_train)\n",
    "print(optimal_params.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "  metrics =  ['accuracy', 'precision', 'recall','auc']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplots(2,2)\n",
    "    plt.plot(history.epochs,  history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epochs, history.history['val_'+metric], color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'accuracy':\n",
    "      plt.ylim([0.8,1])\n",
    "    elif metric == 'precision':\n",
    "      plt.ylim([0.8,1])\n",
    "    elif metric == 'recall':\n",
    "      plt.ylim([0.8,1])\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "plot_metrics(estimator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
